{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bugi\\miniconda3\\envs\\env_skripsi\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Bugi\\miniconda3\\envs\\env_skripsi\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "sys.path.append(os.environ.get('PATH_CUSTOM_MODULES'))\n",
    "\n",
    "import augment_image\n",
    "\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare all basic variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_source = os.environ.get('PATH_DATASET_DESTINATION')\n",
    "scenario_names = ['scenario_1', 'scenario_2', 'scenario_3']\n",
    "dataset_names = ['rimone', 'g1020', 'refuge', 'papila']\n",
    "fold_names = ['fold_1', 'fold_2', 'fold_3', 'fold_4', 'fold_5']\n",
    "labels_name = ['normal', 'glaukoma']\n",
    "image_size = {'rimone': (300,300),\n",
    "            'g1020': (240,300),\n",
    "            'refuge': (300,300),\n",
    "            'papila': (200,300)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the path source and detination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge path source and path destination\n",
    "# for each dataset, scenario, and label\n",
    "path_dataset_src = {}\n",
    "path_dataset_val_test_src = {}\n",
    "path_dataset_aug = {}\n",
    "path_dataset_val_test_dest = {}\n",
    "## create the source path for training data\n",
    "for scenario in scenario_names:\n",
    "    for dataset in dataset_names:\n",
    "        for fold in fold_names:\n",
    "                path_dataset_src[scenario + '_'\n",
    "                                + dataset + '_'\n",
    "                                + fold] = os.path.join(path_source,\n",
    "                                                        scenario,\n",
    "                                                        dataset,\n",
    "                                                        fold,\n",
    "                                                        'train')\n",
    "del scenario, dataset, fold\n",
    "## create the source path for validation and testing data\n",
    "for scenario in scenario_names:\n",
    "    for dataset in dataset_names:\n",
    "        for fold in fold_names:\n",
    "            for data_type in ['val', 'test']:\n",
    "                path_dataset_val_test_src[scenario + '_'\n",
    "                                        + dataset + '_'\n",
    "                                        + fold + '_'\n",
    "                                        + data_type] = os.path.join(path_source,\n",
    "                                                                    scenario,\n",
    "                                                                    dataset,\n",
    "                                                                    fold,\n",
    "                                                                    data_type)\n",
    "del scenario, dataset, fold, data_type\n",
    "## create the destination path a.k.a. augmented path for training data\n",
    "for scenario in scenario_names:\n",
    "    for dataset in dataset_names:\n",
    "        for fold in fold_names:\n",
    "            for label in labels_name:\n",
    "                path_dataset_aug[scenario + '_'\n",
    "                                + dataset + '_'\n",
    "                                + fold + '_'\n",
    "                                + label] = os.path.join(path_source,\n",
    "                                                        scenario,\n",
    "                                                        dataset,\n",
    "                                                        fold,\n",
    "                                                        'train_augmented',\n",
    "                                                        label)\n",
    "del scenario, dataset, fold, label\n",
    "## create the destination path a.k.a. augmented path for validation and testing data\n",
    "for scenario in scenario_names:\n",
    "    for dataset in dataset_names:\n",
    "        for fold in fold_names:\n",
    "            for data_type in ['val', 'test']:\n",
    "                for label in labels_name:\n",
    "                    path_dataset_val_test_dest[scenario + '_'\n",
    "                                                + dataset + '_'\n",
    "                                                + fold + '_'\n",
    "                                                + data_type + '_'\n",
    "                                                + label] = os.path.join(path_source,\n",
    "                                                                        scenario,\n",
    "                                                                        dataset,\n",
    "                                                                        fold,\n",
    "                                                                        data_type,\n",
    "                                                                        label)\n",
    "del scenario, dataset, fold, data_type, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the image data generator for each scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the image data generator\n",
    "## data generator for scenario 1 (without augmentation)\n",
    "datagenerator_s1 = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "## data generator for scenario 2 (with augmentation)\n",
    "datagenerator_s2 = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[1, 1.5]\n",
    ")\n",
    "## data generator for scenario 3 (with augmentation and clahe)\n",
    "datagenerator_s3 = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[1, 1.5],\n",
    "    preprocessing_function=augment_image.clahe_augmentation\n",
    ")\n",
    "## data generator for scenario 3(only clahe)\n",
    "datagenerator_s3_val_test = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    preprocessing_function=augment_image.clahe_augmentation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Augment Directory\n",
    "only run this code once to be safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: scenario_1_rimone_fold_1_normal\n",
      "Directory already exists: scenario_1_rimone_fold_1_glaukoma\n",
      "Directory already exists: scenario_1_rimone_fold_2_normal\n",
      "Directory already exists: scenario_1_rimone_fold_2_glaukoma\n",
      "Directory already exists: scenario_1_rimone_fold_3_normal\n",
      "Directory already exists: scenario_1_rimone_fold_3_glaukoma\n",
      "Directory already exists: scenario_1_rimone_fold_4_normal\n",
      "Directory already exists: scenario_1_rimone_fold_4_glaukoma\n",
      "Directory already exists: scenario_1_rimone_fold_5_normal\n",
      "Directory already exists: scenario_1_rimone_fold_5_glaukoma\n",
      "Directory already exists: scenario_1_g1020_fold_1_normal\n",
      "Directory already exists: scenario_1_g1020_fold_1_glaukoma\n",
      "Directory already exists: scenario_1_g1020_fold_2_normal\n",
      "Directory already exists: scenario_1_g1020_fold_2_glaukoma\n",
      "Directory already exists: scenario_1_g1020_fold_3_normal\n",
      "Directory already exists: scenario_1_g1020_fold_3_glaukoma\n",
      "Directory already exists: scenario_1_g1020_fold_4_normal\n",
      "Directory already exists: scenario_1_g1020_fold_4_glaukoma\n",
      "Directory already exists: scenario_1_g1020_fold_5_normal\n",
      "Directory already exists: scenario_1_g1020_fold_5_glaukoma\n",
      "Directory already exists: scenario_1_refuge_fold_1_normal\n",
      "Directory already exists: scenario_1_refuge_fold_1_glaukoma\n",
      "Directory already exists: scenario_1_refuge_fold_2_normal\n",
      "Directory already exists: scenario_1_refuge_fold_2_glaukoma\n",
      "Directory already exists: scenario_1_refuge_fold_3_normal\n",
      "Directory already exists: scenario_1_refuge_fold_3_glaukoma\n",
      "Directory already exists: scenario_1_refuge_fold_4_normal\n",
      "Directory already exists: scenario_1_refuge_fold_4_glaukoma\n",
      "Directory already exists: scenario_1_refuge_fold_5_normal\n",
      "Directory already exists: scenario_1_refuge_fold_5_glaukoma\n",
      "Directory already exists: scenario_1_papila_fold_1_normal\n",
      "Directory already exists: scenario_1_papila_fold_1_glaukoma\n",
      "Directory already exists: scenario_1_papila_fold_2_normal\n",
      "Directory already exists: scenario_1_papila_fold_2_glaukoma\n",
      "Directory already exists: scenario_1_papila_fold_3_normal\n",
      "Directory already exists: scenario_1_papila_fold_3_glaukoma\n",
      "Directory already exists: scenario_1_papila_fold_4_normal\n",
      "Directory already exists: scenario_1_papila_fold_4_glaukoma\n",
      "Directory already exists: scenario_1_papila_fold_5_normal\n",
      "Directory already exists: scenario_1_papila_fold_5_glaukoma\n",
      "Directory already exists: scenario_2_rimone_fold_1_normal\n",
      "Directory already exists: scenario_2_rimone_fold_1_glaukoma\n",
      "Directory already exists: scenario_2_rimone_fold_2_normal\n",
      "Directory already exists: scenario_2_rimone_fold_2_glaukoma\n",
      "Directory already exists: scenario_2_rimone_fold_3_normal\n",
      "Directory already exists: scenario_2_rimone_fold_3_glaukoma\n",
      "Directory already exists: scenario_2_rimone_fold_4_normal\n",
      "Directory already exists: scenario_2_rimone_fold_4_glaukoma\n",
      "Directory already exists: scenario_2_rimone_fold_5_normal\n",
      "Directory already exists: scenario_2_rimone_fold_5_glaukoma\n",
      "Directory already exists: scenario_2_g1020_fold_1_normal\n",
      "Directory already exists: scenario_2_g1020_fold_1_glaukoma\n",
      "Directory already exists: scenario_2_g1020_fold_2_normal\n",
      "Directory already exists: scenario_2_g1020_fold_2_glaukoma\n",
      "Directory already exists: scenario_2_g1020_fold_3_normal\n",
      "Directory already exists: scenario_2_g1020_fold_3_glaukoma\n",
      "Directory already exists: scenario_2_g1020_fold_4_normal\n",
      "Directory already exists: scenario_2_g1020_fold_4_glaukoma\n",
      "Directory already exists: scenario_2_g1020_fold_5_normal\n",
      "Directory already exists: scenario_2_g1020_fold_5_glaukoma\n",
      "Directory already exists: scenario_2_refuge_fold_1_normal\n",
      "Directory already exists: scenario_2_refuge_fold_1_glaukoma\n",
      "Directory already exists: scenario_2_refuge_fold_2_normal\n",
      "Directory already exists: scenario_2_refuge_fold_2_glaukoma\n",
      "Directory already exists: scenario_2_refuge_fold_3_normal\n",
      "Directory already exists: scenario_2_refuge_fold_3_glaukoma\n",
      "Directory already exists: scenario_2_refuge_fold_4_normal\n",
      "Directory already exists: scenario_2_refuge_fold_4_glaukoma\n",
      "Directory already exists: scenario_2_refuge_fold_5_normal\n",
      "Directory already exists: scenario_2_refuge_fold_5_glaukoma\n",
      "Directory already exists: scenario_2_papila_fold_1_normal\n",
      "Directory already exists: scenario_2_papila_fold_1_glaukoma\n",
      "Directory already exists: scenario_2_papila_fold_2_normal\n",
      "Directory already exists: scenario_2_papila_fold_2_glaukoma\n",
      "Directory already exists: scenario_2_papila_fold_3_normal\n",
      "Directory already exists: scenario_2_papila_fold_3_glaukoma\n",
      "Directory already exists: scenario_2_papila_fold_4_normal\n",
      "Directory already exists: scenario_2_papila_fold_4_glaukoma\n",
      "Directory already exists: scenario_2_papila_fold_5_normal\n",
      "Directory already exists: scenario_2_papila_fold_5_glaukoma\n",
      "Directory already exists: scenario_3_rimone_fold_1_normal\n",
      "Directory already exists: scenario_3_rimone_fold_1_glaukoma\n",
      "Directory already exists: scenario_3_rimone_fold_2_normal\n",
      "Directory already exists: scenario_3_rimone_fold_2_glaukoma\n",
      "Directory already exists: scenario_3_rimone_fold_3_normal\n",
      "Directory already exists: scenario_3_rimone_fold_3_glaukoma\n",
      "Directory already exists: scenario_3_rimone_fold_4_normal\n",
      "Directory already exists: scenario_3_rimone_fold_4_glaukoma\n",
      "Directory already exists: scenario_3_rimone_fold_5_normal\n",
      "Directory already exists: scenario_3_rimone_fold_5_glaukoma\n",
      "Directory already exists: scenario_3_g1020_fold_1_normal\n",
      "Directory already exists: scenario_3_g1020_fold_1_glaukoma\n",
      "Directory already exists: scenario_3_g1020_fold_2_normal\n",
      "Directory already exists: scenario_3_g1020_fold_2_glaukoma\n",
      "Directory already exists: scenario_3_g1020_fold_3_normal\n",
      "Directory already exists: scenario_3_g1020_fold_3_glaukoma\n",
      "Directory already exists: scenario_3_g1020_fold_4_normal\n",
      "Directory already exists: scenario_3_g1020_fold_4_glaukoma\n",
      "Directory already exists: scenario_3_g1020_fold_5_normal\n",
      "Directory already exists: scenario_3_g1020_fold_5_glaukoma\n",
      "Directory already exists: scenario_3_refuge_fold_1_normal\n",
      "Directory already exists: scenario_3_refuge_fold_1_glaukoma\n",
      "Directory already exists: scenario_3_refuge_fold_2_normal\n",
      "Directory already exists: scenario_3_refuge_fold_2_glaukoma\n",
      "Directory already exists: scenario_3_refuge_fold_3_normal\n",
      "Directory already exists: scenario_3_refuge_fold_3_glaukoma\n",
      "Directory already exists: scenario_3_refuge_fold_4_normal\n",
      "Directory already exists: scenario_3_refuge_fold_4_glaukoma\n",
      "Directory already exists: scenario_3_refuge_fold_5_normal\n",
      "Directory already exists: scenario_3_refuge_fold_5_glaukoma\n",
      "Directory already exists: scenario_3_papila_fold_1_normal\n",
      "Directory already exists: scenario_3_papila_fold_1_glaukoma\n",
      "Directory already exists: scenario_3_papila_fold_2_normal\n",
      "Directory already exists: scenario_3_papila_fold_2_glaukoma\n",
      "Directory already exists: scenario_3_papila_fold_3_normal\n",
      "Directory already exists: scenario_3_papila_fold_3_glaukoma\n",
      "Directory already exists: scenario_3_papila_fold_4_normal\n",
      "Directory already exists: scenario_3_papila_fold_4_glaukoma\n",
      "Directory already exists: scenario_3_papila_fold_5_normal\n",
      "Directory already exists: scenario_3_papila_fold_5_glaukoma\n"
     ]
    }
   ],
   "source": [
    "# create the directory for the augmented dataset\n",
    "directory_result = augment_image.create_directory(path_dict=path_dataset_aug)\n",
    "## print the result\n",
    "for key, values in directory_result.items():\n",
    "    if key == 'Already Exists' and values != []:\n",
    "        for value in values:\n",
    "            print('Directory already exists:', value)\n",
    "del key, values, value, directory_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 2\n",
    "**Condition**:\n",
    "- basic augmentation, \n",
    "- rgb color\n",
    "- no clahe\n",
    "#### Import the image into data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the augmentation mode for scenario 2\n",
    "s2_src = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading rimone fold_1 normal...\n",
      "Found 218 images belonging to 1 classes.\n",
      "Loading rimone fold_1 glaukoma...\n",
      "Found 121 images belonging to 1 classes.\n",
      "Loading rimone fold_2 normal...\n",
      "Found 218 images belonging to 1 classes.\n",
      "Loading rimone fold_2 glaukoma...\n",
      "Found 121 images belonging to 1 classes.\n",
      "Loading rimone fold_3 normal...\n",
      "Found 218 images belonging to 1 classes.\n",
      "Loading rimone fold_3 glaukoma...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 121 images belonging to 1 classes.\n",
      "Loading rimone fold_4 normal...\n",
      "Found 219 images belonging to 1 classes.\n",
      "Loading rimone fold_4 glaukoma...\n",
      "Found 120 images belonging to 1 classes.\n",
      "Loading rimone fold_5 normal...\n",
      "Found 219 images belonging to 1 classes.\n",
      "Loading rimone fold_5 glaukoma...\n",
      "Found 120 images belonging to 1 classes.\n",
      "Loading g1020 fold_1 normal...\n",
      "Found 506 images belonging to 1 classes.\n",
      "Loading g1020 fold_1 glaukoma...\n",
      "Found 208 images belonging to 1 classes.\n",
      "Loading g1020 fold_2 normal...\n",
      "Found 506 images belonging to 1 classes.\n",
      "Loading g1020 fold_2 glaukoma...\n",
      "Found 208 images belonging to 1 classes.\n",
      "Loading g1020 fold_3 normal...\n",
      "Found 506 images belonging to 1 classes.\n",
      "Loading g1020 fold_3 glaukoma...\n",
      "Found 208 images belonging to 1 classes.\n",
      "Loading g1020 fold_4 normal...\n",
      "Found 506 images belonging to 1 classes.\n",
      "Loading g1020 fold_4 glaukoma...\n",
      "Found 208 images belonging to 1 classes.\n",
      "Loading g1020 fold_5 normal...\n",
      "Found 507 images belonging to 1 classes.\n",
      "Loading g1020 fold_5 glaukoma...\n",
      "Found 207 images belonging to 1 classes.\n",
      "Loading refuge fold_1 normal...\n",
      "Found 756 images belonging to 1 classes.\n",
      "Loading refuge fold_1 glaukoma...\n",
      "Found 84 images belonging to 1 classes.\n",
      "Loading refuge fold_2 normal...\n",
      "Found 756 images belonging to 1 classes.\n",
      "Loading refuge fold_2 glaukoma...\n",
      "Found 84 images belonging to 1 classes.\n",
      "Loading refuge fold_3 normal...\n",
      "Found 756 images belonging to 1 classes.\n",
      "Loading refuge fold_3 glaukoma...\n",
      "Found 84 images belonging to 1 classes.\n",
      "Loading refuge fold_4 normal...\n",
      "Found 756 images belonging to 1 classes.\n",
      "Loading refuge fold_4 glaukoma...\n",
      "Found 84 images belonging to 1 classes.\n",
      "Loading refuge fold_5 normal...\n",
      "Found 756 images belonging to 1 classes.\n",
      "Loading refuge fold_5 glaukoma...\n",
      "Found 84 images belonging to 1 classes.\n",
      "Loading papila fold_1 normal...\n",
      "Found 232 images belonging to 1 classes.\n",
      "Loading papila fold_1 glaukoma...\n",
      "Found 109 images belonging to 1 classes.\n",
      "Loading papila fold_2 normal...\n",
      "Found 232 images belonging to 1 classes.\n",
      "Loading papila fold_2 glaukoma...\n",
      "Found 109 images belonging to 1 classes.\n",
      "Loading papila fold_3 normal...\n",
      "Found 232 images belonging to 1 classes.\n",
      "Loading papila fold_3 glaukoma...\n",
      "Found 109 images belonging to 1 classes.\n",
      "Loading papila fold_4 normal...\n",
      "Found 233 images belonging to 1 classes.\n",
      "Loading papila fold_4 glaukoma...\n",
      "Found 109 images belonging to 1 classes.\n",
      "Loading papila fold_5 normal...\n",
      "Found 233 images belonging to 1 classes.\n",
      "Loading papila fold_5 glaukoma...\n",
      "Found 109 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# get the image using image data generator\n",
    "## load image using image data generator\n",
    "for dataset in dataset_names:\n",
    "    for fold in fold_names:\n",
    "        for label in labels_name:\n",
    "            print(f'Loading {dataset} {fold} {label}...')\n",
    "            s2_src[dataset + '_'\n",
    "                    + fold + '_'\n",
    "                    + label] = (datagenerator_s2.flow_from_directory(\n",
    "                                path_dataset_src[scenario_names[1] + '_'\n",
    "                                                + dataset + '_'\n",
    "                                                + fold],\n",
    "                                target_size=image_size[dataset],\n",
    "                                class_mode='binary',\n",
    "                                classes=[label],\n",
    "                                shuffle=True,\n",
    "                                seed=1915026018,\n",
    "                                save_to_dir=path_dataset_aug[scenario_names[1] + '_'\n",
    "                                                            + dataset + '_'\n",
    "                                                            + fold + '_'\n",
    "                                                            + label],\n",
    "                                save_prefix=f's2_{dataset}_{fold}_{label}',\n",
    "                                save_format='jpg'))\n",
    "del dataset, fold, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the augmented image & saved it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating augmented image for rimone/fold_1/normal...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 9.53 seconds\n",
      "Generating augmented image for rimone/fold_1/glaukoma...\n",
      "Elapsed time: 5.15 seconds\n",
      "Generating augmented image for rimone/fold_2/normal...\n",
      "Elapsed time: 8.52 seconds\n",
      "Generating augmented image for rimone/fold_2/glaukoma...\n",
      "Elapsed time: 4.47 seconds\n",
      "Generating augmented image for rimone/fold_3/normal...\n",
      "Elapsed time: 7.16 seconds\n",
      "Generating augmented image for rimone/fold_3/glaukoma...\n",
      "Elapsed time: 5.06 seconds\n",
      "Generating augmented image for rimone/fold_4/normal...\n",
      "Elapsed time: 8.07 seconds\n",
      "Generating augmented image for rimone/fold_4/glaukoma...\n",
      "Elapsed time: 4.21 seconds\n",
      "Generating augmented image for rimone/fold_5/normal...\n",
      "Elapsed time: 8.06 seconds\n",
      "Generating augmented image for rimone/fold_5/glaukoma...\n",
      "Elapsed time: 5.03 seconds\n",
      "Generating augmented image for g1020/fold_1/normal...\n",
      "Elapsed time: 55.82 seconds\n",
      "Generating augmented image for g1020/fold_1/glaukoma...\n",
      "Elapsed time: 28.52 seconds\n",
      "Generating augmented image for g1020/fold_2/normal...\n",
      "Elapsed time: 59.03 seconds\n",
      "Generating augmented image for g1020/fold_2/glaukoma...\n",
      "Elapsed time: 26.01 seconds\n",
      "Generating augmented image for g1020/fold_3/normal...\n",
      "Elapsed time: 58.24 seconds\n",
      "Generating augmented image for g1020/fold_3/glaukoma...\n",
      "Elapsed time: 27.99 seconds\n",
      "Generating augmented image for g1020/fold_4/normal...\n",
      "Elapsed time: 79.22 seconds\n",
      "Generating augmented image for g1020/fold_4/glaukoma...\n",
      "Elapsed time: 14.08 seconds\n",
      "Generating augmented image for g1020/fold_5/normal...\n",
      "Elapsed time: 44.64 seconds\n",
      "Generating augmented image for g1020/fold_5/glaukoma...\n",
      "Elapsed time: 14.87 seconds\n",
      "Generating augmented image for refuge/fold_1/normal...\n",
      "Elapsed time: 39.59 seconds\n",
      "Generating augmented image for refuge/fold_1/glaukoma...\n",
      "Elapsed time: 6.28 seconds\n",
      "Generating augmented image for refuge/fold_2/normal...\n",
      "Elapsed time: 43.14 seconds\n",
      "Generating augmented image for refuge/fold_2/glaukoma...\n",
      "Elapsed time: 4.68 seconds\n",
      "Generating augmented image for refuge/fold_3/normal...\n",
      "Elapsed time: 39.12 seconds\n",
      "Generating augmented image for refuge/fold_3/glaukoma...\n",
      "Elapsed time: 4.48 seconds\n",
      "Generating augmented image for refuge/fold_4/normal...\n",
      "Elapsed time: 40.28 seconds\n",
      "Generating augmented image for refuge/fold_4/glaukoma...\n",
      "Elapsed time: 4.38 seconds\n",
      "Generating augmented image for refuge/fold_5/normal...\n",
      "Elapsed time: 38.23 seconds\n",
      "Generating augmented image for refuge/fold_5/glaukoma...\n",
      "Elapsed time: 4.33 seconds\n",
      "Generating augmented image for papila/fold_1/normal...\n",
      "Elapsed time: 12.93 seconds\n",
      "Generating augmented image for papila/fold_1/glaukoma...\n",
      "Elapsed time: 6.20 seconds\n",
      "Generating augmented image for papila/fold_2/normal...\n",
      "Elapsed time: 12.75 seconds\n",
      "Generating augmented image for papila/fold_2/glaukoma...\n",
      "Elapsed time: 6.38 seconds\n",
      "Generating augmented image for papila/fold_3/normal...\n",
      "Elapsed time: 12.78 seconds\n",
      "Generating augmented image for papila/fold_3/glaukoma...\n",
      "Elapsed time: 6.30 seconds\n",
      "Generating augmented image for papila/fold_4/normal...\n",
      "Elapsed time: 13.58 seconds\n",
      "Generating augmented image for papila/fold_4/glaukoma...\n",
      "Elapsed time: 6.44 seconds\n",
      "Generating augmented image for papila/fold_5/normal...\n",
      "Elapsed time: 13.37 seconds\n",
      "Generating augmented image for papila/fold_5/glaukoma...\n",
      "Elapsed time: 6.21 seconds\n"
     ]
    }
   ],
   "source": [
    "augment_image.generate_aug_img(dataset_names=dataset_names,\n",
    "                                fold_names=fold_names,\n",
    "                                labels_names=labels_name,\n",
    "                                batch_datasets=s2_src,\n",
    "                                data_type='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate the augmented image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a varible to store the file name\n",
    "s2_src_fname = {}\n",
    "s2_aug_fname = {}\n",
    "\n",
    "# collecting the source file name\n",
    "for key, value in path_dataset_src.items():\n",
    "    if key.split('_')[1] == '2':\n",
    "        for label in labels_name:\n",
    "            s2_src_fname[key + '_'\n",
    "                        + label] = [file for file in os.listdir(os.path.join(value,label))]\n",
    "del key, value, label\n",
    "\n",
    "# collecting the augmented file name\n",
    "for key, value in path_dataset_aug.items():\n",
    "    if key.split('_')[1] == '2':\n",
    "        s2_aug_fname[key] = [file for file in os.listdir(value)]\n",
    "del key, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>file_count</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>scenario_2_rimone_fold_1_normal</td>\n",
       "      <td>218</td>\n",
       "      <td>source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scenario_2_rimone_fold_1_glaukoma</td>\n",
       "      <td>121</td>\n",
       "      <td>source</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            category  file_count    type\n",
       "0    scenario_2_rimone_fold_1_normal         218  source\n",
       "1  scenario_2_rimone_fold_1_glaukoma         121  source"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the two dictionary into dataframe\n",
    "s2_df_result = pd.concat([pd.DataFrame({\n",
    "                                'category': s2_src_fname.keys(),\n",
    "                                'file_count': [len(value) for value in s2_src_fname.values()],\n",
    "                                'type': 'source'\n",
    "                            }),\n",
    "                            pd.DataFrame({\n",
    "                                'category': s2_aug_fname.keys(),\n",
    "                                'file_count': [len(value) for value in s2_aug_fname.values()],\n",
    "                                'type': 'augmented'\n",
    "                            })])\n",
    "s2_df_result.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>type</th>\n",
       "      <th>augmented</th>\n",
       "      <th>source</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>scenario_2_g1020_fold_1_glaukoma</th>\n",
       "      <td>208.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scenario_2_g1020_fold_1_normal</th>\n",
       "      <td>506.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scenario_2_g1020_fold_2_glaukoma</th>\n",
       "      <td>208.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scenario_2_g1020_fold_2_normal</th>\n",
       "      <td>506.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scenario_2_g1020_fold_3_glaukoma</th>\n",
       "      <td>208.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "type                              augmented  source status\n",
       "category                                                  \n",
       "scenario_2_g1020_fold_1_glaukoma      208.0   208.0  valid\n",
       "scenario_2_g1020_fold_1_normal        506.0   506.0  valid\n",
       "scenario_2_g1020_fold_2_glaukoma      208.0   208.0  valid\n",
       "scenario_2_g1020_fold_2_normal        506.0   506.0  valid\n",
       "scenario_2_g1020_fold_3_glaukoma      208.0   208.0  valid"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validate the file count\n",
    "s2_df_validate = pd.DataFrame(s2_df_result.groupby(['category', 'type']).file_count.sum())\n",
    "\n",
    "s2_df_validate.sort_values(by='category', inplace=True)\n",
    "s2_df_validate = s2_df_validate.pivot_table(index='category',\n",
    "                                            columns='type',\n",
    "                                            values='file_count')\n",
    "\n",
    "s2_df_validate.loc[s2_df_validate.augmented == s2_df_validate.source,\n",
    "                    'status'] = 'valid'\n",
    "s2_df_validate.loc[s2_df_validate.augmented != s2_df_validate.source,\n",
    "                    'status'] = 'invalid'\n",
    "\n",
    "s2_df_validate.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total categories: 40\n",
      "\n",
      "Total valid categories: 40\n",
      "\n",
      "Total invalid categories: 0\n"
     ]
    }
   ],
   "source": [
    "# print the result\n",
    "print(f'Total categories: {len(s2_df_validate)}',\n",
    "    f'\\nTotal valid categories: {len(s2_df_validate[s2_df_validate.status == \"valid\"])}',\n",
    "    f'\\nTotal invalid categories: {len(s2_df_validate[s2_df_validate.status == \"invalid\"])}',\n",
    "    sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 3\n",
    "**Condition**:\n",
    "- basic augmentation, \n",
    "- rgb color, \n",
    "- clahe\n",
    "#### Import the image into data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the augmentation mode for scenario 3\n",
    "s3_src = {}\n",
    "s3_val_test_src = {}\n",
    "s3_file_code_name = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading rimone fold_1 normal...\n",
      "Found 218 images belonging to 1 classes.\n",
      "Loading rimone fold_1 glaukoma...\n",
      "Found 121 images belonging to 1 classes.\n",
      "Loading rimone fold_2 normal...\n",
      "Found 218 images belonging to 1 classes.\n",
      "Loading rimone fold_2 glaukoma...\n",
      "Found 121 images belonging to 1 classes.\n",
      "Loading rimone fold_3 normal...\n",
      "Found 218 images belonging to 1 classes.\n",
      "Loading rimone fold_3 glaukoma...\n",
      "Found 121 images belonging to 1 classes.\n",
      "Loading rimone fold_4 normal...\n",
      "Found 219 images belonging to 1 classes.\n",
      "Loading rimone fold_4 glaukoma...\n",
      "Found 120 images belonging to 1 classes.\n",
      "Loading rimone fold_5 normal...\n",
      "Found 219 images belonging to 1 classes.\n",
      "Loading rimone fold_5 glaukoma...\n",
      "Found 120 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading g1020 fold_1 normal...\n",
      "Found 506 images belonging to 1 classes.\n",
      "Loading g1020 fold_1 glaukoma...\n",
      "Found 208 images belonging to 1 classes.\n",
      "Loading g1020 fold_2 normal...\n",
      "Found 506 images belonging to 1 classes.\n",
      "Loading g1020 fold_2 glaukoma...\n",
      "Found 208 images belonging to 1 classes.\n",
      "Loading g1020 fold_3 normal...\n",
      "Found 506 images belonging to 1 classes.\n",
      "Loading g1020 fold_3 glaukoma...\n",
      "Found 208 images belonging to 1 classes.\n",
      "Loading g1020 fold_4 normal...\n",
      "Found 506 images belonging to 1 classes.\n",
      "Loading g1020 fold_4 glaukoma...\n",
      "Found 208 images belonging to 1 classes.\n",
      "Loading g1020 fold_5 normal...\n",
      "Found 507 images belonging to 1 classes.\n",
      "Loading g1020 fold_5 glaukoma...\n",
      "Found 207 images belonging to 1 classes.\n",
      "Loading refuge fold_1 normal...\n",
      "Found 756 images belonging to 1 classes.\n",
      "Loading refuge fold_1 glaukoma...\n",
      "Found 84 images belonging to 1 classes.\n",
      "Loading refuge fold_2 normal...\n",
      "Found 756 images belonging to 1 classes.\n",
      "Loading refuge fold_2 glaukoma...\n",
      "Found 84 images belonging to 1 classes.\n",
      "Loading refuge fold_3 normal...\n",
      "Found 756 images belonging to 1 classes.\n",
      "Loading refuge fold_3 glaukoma...\n",
      "Found 84 images belonging to 1 classes.\n",
      "Loading refuge fold_4 normal...\n",
      "Found 756 images belonging to 1 classes.\n",
      "Loading refuge fold_4 glaukoma...\n",
      "Found 84 images belonging to 1 classes.\n",
      "Loading refuge fold_5 normal...\n",
      "Found 756 images belonging to 1 classes.\n",
      "Loading refuge fold_5 glaukoma...\n",
      "Found 84 images belonging to 1 classes.\n",
      "Loading papila fold_1 normal...\n",
      "Found 232 images belonging to 1 classes.\n",
      "Loading papila fold_1 glaukoma...\n",
      "Found 109 images belonging to 1 classes.\n",
      "Loading papila fold_2 normal...\n",
      "Found 232 images belonging to 1 classes.\n",
      "Loading papila fold_2 glaukoma...\n",
      "Found 109 images belonging to 1 classes.\n",
      "Loading papila fold_3 normal...\n",
      "Found 232 images belonging to 1 classes.\n",
      "Loading papila fold_3 glaukoma...\n",
      "Found 109 images belonging to 1 classes.\n",
      "Loading papila fold_4 normal...\n",
      "Found 233 images belonging to 1 classes.\n",
      "Loading papila fold_4 glaukoma...\n",
      "Found 109 images belonging to 1 classes.\n",
      "Loading papila fold_5 normal...\n",
      "Found 233 images belonging to 1 classes.\n",
      "Loading papila fold_5 glaukoma...\n",
      "Found 109 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# load image using image data generator for training data\n",
    "for dataset in dataset_names:\n",
    "    for fold in fold_names:\n",
    "        for label in labels_name:\n",
    "            print(f'Loading {dataset} {fold} {label}...')\n",
    "            s3_src[dataset + '_'\n",
    "                    + fold + '_'\n",
    "                    + label] = (datagenerator_s3.flow_from_directory(\n",
    "                                path_dataset_src[scenario_names[2] + '_'\n",
    "                                                + dataset + '_'\n",
    "                                                + fold],\n",
    "                                target_size=image_size[dataset],\n",
    "                                class_mode='binary',\n",
    "                                classes=[label],\n",
    "                                shuffle=True,\n",
    "                                seed=1915026018,\n",
    "                                save_to_dir=path_dataset_aug[scenario_names[2] + '_'\n",
    "                                                            + dataset + '_'\n",
    "                                                            + fold + '_'\n",
    "                                                            + label],\n",
    "                                save_prefix=f's3_{dataset}_{fold}_{label}',\n",
    "                                save_format='jpg'))\n",
    "del dataset, fold, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading rimone fold_1 val normal...\n",
      "Found 32 images belonging to 1 classes.\n",
      "Loading rimone fold_1 val glaukoma...\n",
      "Found 17 images belonging to 1 classes.\n",
      "Loading rimone fold_1 test normal...\n",
      "Found 63 images belonging to 1 classes.\n",
      "Loading rimone fold_1 test glaukoma...\n",
      "Found 34 images belonging to 1 classes.\n",
      "Loading rimone fold_2 val normal...\n",
      "Found 32 images belonging to 1 classes.\n",
      "Loading rimone fold_2 val glaukoma...\n",
      "Found 17 images belonging to 1 classes.\n",
      "Loading rimone fold_2 test normal...\n",
      "Found 63 images belonging to 1 classes.\n",
      "Loading rimone fold_2 test glaukoma...\n",
      "Found 34 images belonging to 1 classes.\n",
      "Loading rimone fold_3 val normal...\n",
      "Found 32 images belonging to 1 classes.\n",
      "Loading rimone fold_3 val glaukoma...\n",
      "Found 17 images belonging to 1 classes.\n",
      "Loading rimone fold_3 test normal...\n",
      "Found 63 images belonging to 1 classes.\n",
      "Loading rimone fold_3 test glaukoma...\n",
      "Found 34 images belonging to 1 classes.\n",
      "Loading rimone fold_4 val normal...\n",
      "Found 32 images belonging to 1 classes.\n",
      "Loading rimone fold_4 val glaukoma...\n",
      "Found 17 images belonging to 1 classes.\n",
      "Loading rimone fold_4 test normal...\n",
      "Found 62 images belonging to 1 classes.\n",
      "Loading rimone fold_4 test glaukoma...\n",
      "Found 35 images belonging to 1 classes.\n",
      "Loading rimone fold_5 val normal...\n",
      "Found 32 images belonging to 1 classes.\n",
      "Loading rimone fold_5 val glaukoma...\n",
      "Found 17 images belonging to 1 classes.\n",
      "Loading rimone fold_5 test normal...\n",
      "Found 62 images belonging to 1 classes.\n",
      "Loading rimone fold_5 test glaukoma...\n",
      "Found 35 images belonging to 1 classes.\n",
      "Loading g1020 fold_1 val normal...\n",
      "Found 73 images belonging to 1 classes.\n",
      "Loading g1020 fold_1 val glaukoma...\n",
      "Found 29 images belonging to 1 classes.\n",
      "Loading g1020 fold_1 test normal...\n",
      "Found 145 images belonging to 1 classes.\n",
      "Loading g1020 fold_1 test glaukoma...\n",
      "Found 59 images belonging to 1 classes.\n",
      "Loading g1020 fold_2 val normal...\n",
      "Found 73 images belonging to 1 classes.\n",
      "Loading g1020 fold_2 val glaukoma...\n",
      "Found 29 images belonging to 1 classes.\n",
      "Loading g1020 fold_2 test normal...\n",
      "Found 145 images belonging to 1 classes.\n",
      "Loading g1020 fold_2 test glaukoma...\n",
      "Found 59 images belonging to 1 classes.\n",
      "Loading g1020 fold_3 val normal...\n",
      "Found 73 images belonging to 1 classes.\n",
      "Loading g1020 fold_3 val glaukoma...\n",
      "Found 29 images belonging to 1 classes.\n",
      "Loading g1020 fold_3 test normal...\n",
      "Found 145 images belonging to 1 classes.\n",
      "Loading g1020 fold_3 test glaukoma...\n",
      "Found 59 images belonging to 1 classes.\n",
      "Loading g1020 fold_4 val normal...\n",
      "Found 73 images belonging to 1 classes.\n",
      "Loading g1020 fold_4 val glaukoma...\n",
      "Found 29 images belonging to 1 classes.\n",
      "Loading g1020 fold_4 test normal...\n",
      "Found 145 images belonging to 1 classes.\n",
      "Loading g1020 fold_4 test glaukoma...\n",
      "Found 59 images belonging to 1 classes.\n",
      "Loading g1020 fold_5 val normal...\n",
      "Found 73 images belonging to 1 classes.\n",
      "Loading g1020 fold_5 val glaukoma...\n",
      "Found 29 images belonging to 1 classes.\n",
      "Loading g1020 fold_5 test normal...\n",
      "Found 144 images belonging to 1 classes.\n",
      "Loading g1020 fold_5 test glaukoma...\n",
      "Found 60 images belonging to 1 classes.\n",
      "Loading refuge fold_1 val normal...\n",
      "Found 108 images belonging to 1 classes.\n",
      "Loading refuge fold_1 val glaukoma...\n",
      "Found 12 images belonging to 1 classes.\n",
      "Loading refuge fold_1 test normal...\n",
      "Found 216 images belonging to 1 classes.\n",
      "Loading refuge fold_1 test glaukoma...\n",
      "Found 24 images belonging to 1 classes.\n",
      "Loading refuge fold_2 val normal...\n",
      "Found 108 images belonging to 1 classes.\n",
      "Loading refuge fold_2 val glaukoma...\n",
      "Found 12 images belonging to 1 classes.\n",
      "Loading refuge fold_2 test normal...\n",
      "Found 216 images belonging to 1 classes.\n",
      "Loading refuge fold_2 test glaukoma...\n",
      "Found 24 images belonging to 1 classes.\n",
      "Loading refuge fold_3 val normal...\n",
      "Found 108 images belonging to 1 classes.\n",
      "Loading refuge fold_3 val glaukoma...\n",
      "Found 12 images belonging to 1 classes.\n",
      "Loading refuge fold_3 test normal...\n",
      "Found 216 images belonging to 1 classes.\n",
      "Loading refuge fold_3 test glaukoma...\n",
      "Found 24 images belonging to 1 classes.\n",
      "Loading refuge fold_4 val normal...\n",
      "Found 108 images belonging to 1 classes.\n",
      "Loading refuge fold_4 val glaukoma...\n",
      "Found 12 images belonging to 1 classes.\n",
      "Loading refuge fold_4 test normal...\n",
      "Found 216 images belonging to 1 classes.\n",
      "Loading refuge fold_4 test glaukoma...\n",
      "Found 24 images belonging to 1 classes.\n",
      "Loading refuge fold_5 val normal...\n",
      "Found 108 images belonging to 1 classes.\n",
      "Loading refuge fold_5 val glaukoma...\n",
      "Found 12 images belonging to 1 classes.\n",
      "Loading refuge fold_5 test normal...\n",
      "Found 216 images belonging to 1 classes.\n",
      "Loading refuge fold_5 test glaukoma...\n",
      "Found 24 images belonging to 1 classes.\n",
      "Loading papila fold_1 val normal...\n",
      "Found 34 images belonging to 1 classes.\n",
      "Loading papila fold_1 val glaukoma...\n",
      "Found 15 images belonging to 1 classes.\n",
      "Loading papila fold_1 test normal...\n",
      "Found 67 images belonging to 1 classes.\n",
      "Loading papila fold_1 test glaukoma...\n",
      "Found 31 images belonging to 1 classes.\n",
      "Loading papila fold_2 val normal...\n",
      "Found 34 images belonging to 1 classes.\n",
      "Loading papila fold_2 val glaukoma...\n",
      "Found 15 images belonging to 1 classes.\n",
      "Loading papila fold_2 test normal...\n",
      "Found 67 images belonging to 1 classes.\n",
      "Loading papila fold_2 test glaukoma...\n",
      "Found 31 images belonging to 1 classes.\n",
      "Loading papila fold_3 val normal...\n",
      "Found 34 images belonging to 1 classes.\n",
      "Loading papila fold_3 val glaukoma...\n",
      "Found 15 images belonging to 1 classes.\n",
      "Loading papila fold_3 test normal...\n",
      "Found 67 images belonging to 1 classes.\n",
      "Loading papila fold_3 test glaukoma...\n",
      "Found 31 images belonging to 1 classes.\n",
      "Loading papila fold_4 val normal...\n",
      "Found 34 images belonging to 1 classes.\n",
      "Loading papila fold_4 val glaukoma...\n",
      "Found 15 images belonging to 1 classes.\n",
      "Loading papila fold_4 test normal...\n",
      "Found 66 images belonging to 1 classes.\n",
      "Loading papila fold_4 test glaukoma...\n",
      "Found 31 images belonging to 1 classes.\n",
      "Loading papila fold_5 val normal...\n",
      "Found 34 images belonging to 1 classes.\n",
      "Loading papila fold_5 val glaukoma...\n",
      "Found 15 images belonging to 1 classes.\n",
      "Loading papila fold_5 test normal...\n",
      "Found 66 images belonging to 1 classes.\n",
      "Loading papila fold_5 test glaukoma...\n",
      "Found 31 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# load image using image data generator for validation and test data\n",
    "for dataset in dataset_names:\n",
    "    for fold in fold_names:\n",
    "        for data_type in ['val', 'test']:\n",
    "            for label in labels_name:\n",
    "                print(f'Loading {dataset} {fold} {data_type} {label}...')\n",
    "                s3_val_test_src[dataset + '_'\n",
    "                                + fold + '_'\n",
    "                                + data_type + '_'\n",
    "                                + label] = (datagenerator_s3_val_test.flow_from_directory(\n",
    "                                            path_dataset_val_test_src[scenario_names[2] + '_'\n",
    "                                                                    + dataset + '_'\n",
    "                                                                    + fold + '_'\n",
    "                                                                    + data_type],\n",
    "                                            target_size=image_size[dataset],\n",
    "                                            class_mode='binary',\n",
    "                                            classes=[label],\n",
    "                                            shuffle=True,\n",
    "                                            seed=1915026018,\n",
    "                                            save_to_dir=path_dataset_val_test_dest[scenario_names[2] + '_'\n",
    "                                                                                    + dataset + '_'\n",
    "                                                                                    + fold + '_'\n",
    "                                                                                    + data_type + '_'\n",
    "                                                                                    + label],\n",
    "                                            save_prefix=f's3_{dataset}_{fold}_{data_type}_{label}',\n",
    "                                            save_format='jpg'))\n",
    "                s3_file_code_name.append(f's3_{dataset}_{fold}_{data_type}_{label}')\n",
    "del dataset, fold, data_type, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the augmented image & saved it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating augmented image for rimone/fold_1/normal...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 53.67 seconds\n",
      "Generating augmented image for rimone/fold_1/glaukoma...\n",
      "Elapsed time: 24.23 seconds\n",
      "Generating augmented image for rimone/fold_2/normal...\n",
      "Elapsed time: 39.54 seconds\n",
      "Generating augmented image for rimone/fold_2/glaukoma...\n",
      "Elapsed time: 22.64 seconds\n",
      "Generating augmented image for rimone/fold_3/normal...\n",
      "Elapsed time: 39.28 seconds\n",
      "Generating augmented image for rimone/fold_3/glaukoma...\n",
      "Elapsed time: 21.82 seconds\n",
      "Generating augmented image for rimone/fold_4/normal...\n",
      "Elapsed time: 39.27 seconds\n",
      "Generating augmented image for rimone/fold_4/glaukoma...\n",
      "Elapsed time: 21.44 seconds\n",
      "Generating augmented image for rimone/fold_5/normal...\n",
      "Elapsed time: 39.38 seconds\n",
      "Generating augmented image for rimone/fold_5/glaukoma...\n",
      "Elapsed time: 22.08 seconds\n",
      "Generating augmented image for g1020/fold_1/normal...\n",
      "Elapsed time: 70.65 seconds\n",
      "Generating augmented image for g1020/fold_1/glaukoma...\n",
      "Elapsed time: 27.64 seconds\n",
      "Generating augmented image for g1020/fold_2/normal...\n",
      "Elapsed time: 67.53 seconds\n",
      "Generating augmented image for g1020/fold_2/glaukoma...\n",
      "Elapsed time: 27.35 seconds\n",
      "Generating augmented image for g1020/fold_3/normal...\n",
      "Elapsed time: 82.71 seconds\n",
      "Generating augmented image for g1020/fold_3/glaukoma...\n",
      "Elapsed time: 33.21 seconds\n",
      "Generating augmented image for g1020/fold_4/normal...\n",
      "Elapsed time: 95.63 seconds\n",
      "Generating augmented image for g1020/fold_4/glaukoma...\n",
      "Elapsed time: 38.82 seconds\n",
      "Generating augmented image for g1020/fold_5/normal...\n",
      "Elapsed time: 87.00 seconds\n",
      "Generating augmented image for g1020/fold_5/glaukoma...\n",
      "Elapsed time: 43.88 seconds\n",
      "Generating augmented image for refuge/fold_1/normal...\n",
      "Elapsed time: 189.72 seconds\n",
      "Generating augmented image for refuge/fold_1/glaukoma...\n",
      "Elapsed time: 20.44 seconds\n",
      "Generating augmented image for refuge/fold_2/normal...\n",
      "Elapsed time: 170.38 seconds\n",
      "Generating augmented image for refuge/fold_2/glaukoma...\n",
      "Elapsed time: 16.93 seconds\n",
      "Generating augmented image for refuge/fold_3/normal...\n",
      "Elapsed time: 155.22 seconds\n",
      "Generating augmented image for refuge/fold_3/glaukoma...\n",
      "Elapsed time: 18.48 seconds\n",
      "Generating augmented image for refuge/fold_4/normal...\n",
      "Elapsed time: 141.47 seconds\n",
      "Generating augmented image for refuge/fold_4/glaukoma...\n",
      "Elapsed time: 13.06 seconds\n",
      "Generating augmented image for refuge/fold_5/normal...\n",
      "Elapsed time: 116.42 seconds\n",
      "Generating augmented image for refuge/fold_5/glaukoma...\n",
      "Elapsed time: 12.56 seconds\n",
      "Generating augmented image for papila/fold_1/normal...\n",
      "Elapsed time: 29.04 seconds\n",
      "Generating augmented image for papila/fold_1/glaukoma...\n",
      "Elapsed time: 13.69 seconds\n",
      "Generating augmented image for papila/fold_2/normal...\n",
      "Elapsed time: 28.18 seconds\n",
      "Generating augmented image for papila/fold_2/glaukoma...\n",
      "Elapsed time: 13.32 seconds\n",
      "Generating augmented image for papila/fold_3/normal...\n",
      "Elapsed time: 28.52 seconds\n",
      "Generating augmented image for papila/fold_3/glaukoma...\n",
      "Elapsed time: 16.31 seconds\n",
      "Generating augmented image for papila/fold_4/normal...\n",
      "Elapsed time: 31.86 seconds\n",
      "Generating augmented image for papila/fold_4/glaukoma...\n",
      "Elapsed time: 15.53 seconds\n",
      "Generating augmented image for papila/fold_5/normal...\n",
      "Elapsed time: 28.66 seconds\n",
      "Generating augmented image for papila/fold_5/glaukoma...\n",
      "Elapsed time: 13.58 seconds\n"
     ]
    }
   ],
   "source": [
    "# generate the augmented image for training data\n",
    "augment_image.generate_aug_img(dataset_names=dataset_names,\n",
    "                                fold_names=fold_names,\n",
    "                                labels_names=labels_name,\n",
    "                                batch_datasets=s3_src,\n",
    "                                data_type='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating augmented image for rimone/fold_1/val...\n",
      "Elapsed time: 7.39 seconds\n",
      "Generating augmented image for rimone/fold_1/test...\n",
      "Elapsed time: 12.72 seconds\n",
      "Generating augmented image for rimone/fold_2/val...\n",
      "Elapsed time: 6.18 seconds\n",
      "Generating augmented image for rimone/fold_2/test...\n",
      "Elapsed time: 12.33 seconds\n",
      "Generating augmented image for rimone/fold_3/val...\n",
      "Elapsed time: 6.25 seconds\n",
      "Generating augmented image for rimone/fold_3/test...\n",
      "Elapsed time: 12.40 seconds\n",
      "Generating augmented image for rimone/fold_4/val...\n",
      "Elapsed time: 6.20 seconds\n",
      "Generating augmented image for rimone/fold_4/test...\n",
      "Elapsed time: 12.64 seconds\n",
      "Generating augmented image for rimone/fold_5/val...\n",
      "Elapsed time: 6.33 seconds\n",
      "Generating augmented image for rimone/fold_5/test...\n",
      "Elapsed time: 12.36 seconds\n",
      "Generating augmented image for g1020/fold_1/val...\n",
      "Elapsed time: 14.02 seconds\n",
      "Generating augmented image for g1020/fold_1/test...\n",
      "Elapsed time: 27.97 seconds\n",
      "Generating augmented image for g1020/fold_2/val...\n",
      "Elapsed time: 13.88 seconds\n",
      "Generating augmented image for g1020/fold_2/test...\n",
      "Elapsed time: 28.45 seconds\n",
      "Generating augmented image for g1020/fold_3/val...\n",
      "Elapsed time: 17.10 seconds\n",
      "Generating augmented image for g1020/fold_3/test...\n",
      "Elapsed time: 31.12 seconds\n",
      "Generating augmented image for g1020/fold_4/val...\n",
      "Elapsed time: 15.07 seconds\n",
      "Generating augmented image for g1020/fold_4/test...\n",
      "Elapsed time: 30.26 seconds\n",
      "Generating augmented image for g1020/fold_5/val...\n",
      "Elapsed time: 15.16 seconds\n",
      "Generating augmented image for g1020/fold_5/test...\n",
      "Elapsed time: 34.38 seconds\n",
      "Generating augmented image for refuge/fold_1/val...\n",
      "Elapsed time: 22.49 seconds\n",
      "Generating augmented image for refuge/fold_1/test...\n",
      "Elapsed time: 42.23 seconds\n",
      "Generating augmented image for refuge/fold_2/val...\n",
      "Elapsed time: 19.85 seconds\n",
      "Generating augmented image for refuge/fold_2/test...\n",
      "Elapsed time: 39.79 seconds\n",
      "Generating augmented image for refuge/fold_3/val...\n",
      "Elapsed time: 20.53 seconds\n",
      "Generating augmented image for refuge/fold_3/test...\n",
      "Elapsed time: 44.26 seconds\n",
      "Generating augmented image for refuge/fold_4/val...\n",
      "Elapsed time: 19.39 seconds\n",
      "Generating augmented image for refuge/fold_4/test...\n",
      "Elapsed time: 40.80 seconds\n",
      "Generating augmented image for refuge/fold_5/val...\n",
      "Elapsed time: 21.88 seconds\n",
      "Generating augmented image for refuge/fold_5/test...\n",
      "Elapsed time: 53.83 seconds\n",
      "Generating augmented image for papila/fold_1/val...\n",
      "Elapsed time: 7.06 seconds\n",
      "Generating augmented image for papila/fold_1/test...\n",
      "Elapsed time: 12.82 seconds\n",
      "Generating augmented image for papila/fold_2/val...\n",
      "Elapsed time: 6.73 seconds\n",
      "Generating augmented image for papila/fold_2/test...\n",
      "Elapsed time: 13.72 seconds\n",
      "Generating augmented image for papila/fold_3/val...\n",
      "Elapsed time: 6.30 seconds\n",
      "Generating augmented image for papila/fold_3/test...\n",
      "Elapsed time: 13.60 seconds\n",
      "Generating augmented image for papila/fold_4/val...\n",
      "Elapsed time: 6.85 seconds\n",
      "Generating augmented image for papila/fold_4/test...\n",
      "Elapsed time: 15.18 seconds\n",
      "Generating augmented image for papila/fold_5/val...\n",
      "Elapsed time: 6.38 seconds\n",
      "Generating augmented image for papila/fold_5/test...\n",
      "Elapsed time: 12.74 seconds\n"
     ]
    }
   ],
   "source": [
    "# generate the augmented image for validation and testing data\n",
    "augment_image.generate_aug_img(dataset_names=dataset_names,\n",
    "                                fold_names=fold_names,\n",
    "                                labels_names=labels_name,\n",
    "                                batch_datasets=s3_val_test_src,\n",
    "                                data_type='val_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate the augmented image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a varible to store the file name\n",
    "s3_src_fname = {}\n",
    "s3_aug_fname = {}\n",
    "\n",
    "# collecting the source file name\n",
    "for key, value in path_dataset_src.items():\n",
    "    if key.split('_')[1] == '3':\n",
    "        for label in labels_name:\n",
    "            s3_src_fname[key + '_'\n",
    "                        + label] = [file for file in os.listdir(os.path.join(value,label))]\n",
    "del key, value, label\n",
    "\n",
    "# collecting the augmented file name\n",
    "for key, value in path_dataset_aug.items():\n",
    "    if key.split('_')[1] == '3':\n",
    "        s3_aug_fname[key] = [file for file in os.listdir(value)]\n",
    "del key, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>file_count</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>scenario_3_rimone_fold_1_normal</td>\n",
       "      <td>218</td>\n",
       "      <td>source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scenario_3_rimone_fold_1_glaukoma</td>\n",
       "      <td>121</td>\n",
       "      <td>source</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            category  file_count    type\n",
       "0    scenario_3_rimone_fold_1_normal         218  source\n",
       "1  scenario_3_rimone_fold_1_glaukoma         121  source"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the two dictionary into dataframe\n",
    "s3_df_result = pd.concat([pd.DataFrame({\n",
    "                                'category': s3_src_fname.keys(),\n",
    "                                'file_count': [len(value) for value in s3_src_fname.values()],\n",
    "                                'type': 'source'\n",
    "                            }),\n",
    "                            pd.DataFrame({\n",
    "                                'category': s3_aug_fname.keys(),\n",
    "                                'file_count': [len(value) for value in s3_aug_fname.values()],\n",
    "                                'type': 'augmented'\n",
    "                            })])\n",
    "s3_df_result.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>type</th>\n",
       "      <th>augmented</th>\n",
       "      <th>source</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>scenario_3_g1020_fold_1_glaukoma</th>\n",
       "      <td>208.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scenario_3_g1020_fold_1_normal</th>\n",
       "      <td>506.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scenario_3_g1020_fold_2_glaukoma</th>\n",
       "      <td>208.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scenario_3_g1020_fold_2_normal</th>\n",
       "      <td>506.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scenario_3_g1020_fold_3_glaukoma</th>\n",
       "      <td>208.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "type                              augmented  source status\n",
       "category                                                  \n",
       "scenario_3_g1020_fold_1_glaukoma      208.0   208.0  valid\n",
       "scenario_3_g1020_fold_1_normal        506.0   506.0  valid\n",
       "scenario_3_g1020_fold_2_glaukoma      208.0   208.0  valid\n",
       "scenario_3_g1020_fold_2_normal        506.0   506.0  valid\n",
       "scenario_3_g1020_fold_3_glaukoma      208.0   208.0  valid"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validate the file count\n",
    "s3_df_validate = pd.DataFrame(s3_df_result.groupby(['category', 'type']).file_count.sum())\n",
    "\n",
    "s3_df_validate.sort_values(by='category', inplace=True)\n",
    "s3_df_validate = s3_df_validate.pivot_table(index='category',\n",
    "                                            columns='type',\n",
    "                                            values='file_count')\n",
    "\n",
    "s3_df_validate.loc[s3_df_validate.augmented == s3_df_validate.source,\n",
    "                    'status'] = 'valid'\n",
    "s3_df_validate.loc[s3_df_validate.augmented != s3_df_validate.source,\n",
    "                    'status'] = 'invalid'\n",
    "\n",
    "s3_df_validate.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total categories: 40\n",
      "\n",
      "Total valid categories: 40\n",
      "\n",
      "Total invalid categories: 0\n"
     ]
    }
   ],
   "source": [
    "# print the result\n",
    "print(f'Total categories: {len(s3_df_validate)}',\n",
    "    f'\\nTotal valid categories: {len(s3_df_validate[s3_df_validate.status == \"valid\"])}',\n",
    "    f'\\nTotal invalid categories: {len(s3_df_validate[s3_df_validate.status == \"invalid\"])}',\n",
    "    sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove the previous image\n",
    "##### Getting the image file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variable to store the file name\n",
    "s3_rm_file, s3_aug_file = augment_image.get_file(files_code=s3_file_code_name,\n",
    "                                            path_dest=path_dataset_val_test_dest,\n",
    "                                            scenario=scenario_names[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validate the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>category</th>\n",
       "      <th>file_path</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [type, category, file_path, file_name]\n",
       "Index: []"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the dataframe to store the result\n",
    "s3_df_file_check = pd.DataFrame(columns = ['type',\n",
    "                                        'category',\n",
    "                                        'file_path',\n",
    "                                        'file_name'])\n",
    "s3_df_file_check.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the file name that will be removed result into the dataframe\n",
    "for category, files_list in s3_rm_file.items():\n",
    "    for file in files_list:\n",
    "        s3_df_file_check.loc[len(s3_df_file_check)] = ['remove',\n",
    "                                                    category[3:].replace('_', ' '),\n",
    "                                                    file,\n",
    "                                                    os.path.basename(file)]\n",
    "del category, files_list, file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the file name that is augmented into the dataframe\n",
    "for category, Files_list in s3_aug_file.items():\n",
    "    for file in Files_list:\n",
    "        s3_df_file_check.loc[len(s3_df_file_check)] = ['augment',\n",
    "                                                    category[3:].replace('_', ' '),\n",
    "                                                    file,\n",
    "                                                    os.path.basename(file)]\n",
    "del category, Files_list, file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type         0\n",
       "category     0\n",
       "file_path    0\n",
       "file_name    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_df_file_check.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>type</th>\n",
       "      <th>augment</th>\n",
       "      <th>remove</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>g1020 fold 1 test glaukoma</th>\n",
       "      <td>59.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g1020 fold 1 test normal</th>\n",
       "      <td>145.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g1020 fold 1 val glaukoma</th>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "type                        augment  remove status\n",
       "category                                          \n",
       "g1020 fold 1 test glaukoma     59.0    59.0  valid\n",
       "g1020 fold 1 test normal      145.0   145.0  valid\n",
       "g1020 fold 1 val glaukoma      29.0    29.0  valid"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# handle the result into the compare able shape\n",
    "s3_df_validate = pd.DataFrame(s3_df_file_check.groupby(by=['category',\n",
    "                                                        'type']).count()['file_name'])\n",
    "\n",
    "\n",
    "s3_df_validate = s3_df_validate.pivot_table(values='file_name',\n",
    "                                            index='category',\n",
    "                                            columns='type')\n",
    "s3_df_validate.loc[s3_df_validate.augment == s3_df_validate.remove,\n",
    "                    'status'] = 'valid'\n",
    "s3_df_validate.loc[s3_df_validate.augment != s3_df_validate.remove,\n",
    "                    'status'] = 'invalid'\n",
    "s3_df_validate.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total categories: 80\n",
      "valid file(s)   : 80\n",
      "invalid file(s) : 0\n"
     ]
    }
   ],
   "source": [
    "# print the result\n",
    "print(f'total categories: {s3_df_validate.shape[0]}',\n",
    "        f'valid file(s)   : {s3_df_validate.loc[s3_df_validate.status == \"valid\"].shape[0]}',\n",
    "        f'invalid file(s) : {s3_df_validate.loc[s3_df_validate.status == \"invalid\"].shape[0]}',\n",
    "        sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removing the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files removed: 31\n",
      "Files already removed: 0\n"
     ]
    }
   ],
   "source": [
    "for files in s3_rm_file.values():\n",
    "    result_status = augment_image.remove_file(files)\n",
    "\n",
    "print(f'Files removed: {len(result_status[\"Success\"])}',\n",
    "        f'Files already removed: {len(result_status[\"Not Found\"])}',\n",
    "        sep='\\n')\n",
    "\n",
    "del files, result_status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing scenario one augmented directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory removed: 20\n",
      "Directory already removed: 0\n"
     ]
    }
   ],
   "source": [
    "s1_rmdir = []\n",
    "for scenario in scenario_names:\n",
    "    for dataset in dataset_names:\n",
    "        for fold in fold_names:\n",
    "            s1_rmdir.append(os.path.join(path_source,\n",
    "                                        scenario,\n",
    "                                        dataset,\n",
    "                                        fold,\n",
    "                                        'train_augmented'))\n",
    "    break\n",
    "\n",
    "result_status = augment_image.remove_dir(s1_rmdir)\n",
    "print(f'Directory removed: {len(result_status[\"Success\"])}',\n",
    "        f'Directory already removed: {len(result_status[\"Not Found\"])}',\n",
    "        sep='\\n')\n",
    "\n",
    "del scenario, dataset, fold"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_skripsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
