{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "sys.path.append(os.environ.get('PATH_CUSTOM_MODULES'))\n",
    "\n",
    "import modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare all basic variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_source = os.environ.get('PATH_DATASET_DESTINATION')\n",
    "path_pretrained = os.environ.get('PATH_PRETRAINED')\n",
    "path_model_storage = os.environ.get('PATH_MODEL')\n",
    "path_result = os.environ.get('PATH_TRAIN_RESULT')\n",
    "scenario_names = ['scenario_1', 'scenario_2', 'scenario_3']\n",
    "dataset_names = ['rimone', 'g1020', 'refuge', 'papila']\n",
    "fold_names = ['fold_1', 'fold_2', 'fold_3', 'fold_4', 'fold_5']\n",
    "pre_trained_models = ['mobilenet_v2', 'mobilenet_v3small', 'mobilenet_v3large',\n",
    "                'efficientnet_v2s', 'efficientnet_v2m', 'efficientnet_v2l']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the path source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset_src = {}\n",
    "\n",
    "for scenario in scenario_names:\n",
    "    for dataset in dataset_names:\n",
    "        for fold in fold_names:\n",
    "            if scenario == 'scenario_1':\n",
    "                    train = 'train'\n",
    "            else:\n",
    "                train = 'train_augmented'\n",
    "\n",
    "            for data_type in [train, 'val', 'test']:\n",
    "                path_dataset_src[f'{scenario}_'\n",
    "                                + f'{dataset}_'\n",
    "                                + f'{fold}_'\n",
    "                                + f'{data_type}'] = os.path.join(path_source,\n",
    "                                                                scenario,\n",
    "                                                                dataset,\n",
    "                                                                fold,\n",
    "                                                                data_type)\n",
    "del scenario, dataset, fold, data_type, train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the image data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image data generator for scenario_1 rimone fold_1 train\n",
      "Found 339 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 rimone fold_1 val\n",
      "Found 49 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 rimone fold_1 test\n",
      "Found 97 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 rimone fold_2 train\n",
      "Found 339 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 rimone fold_2 val\n",
      "Found 49 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 rimone fold_2 test\n",
      "Found 97 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 rimone fold_3 train\n",
      "Found 339 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 rimone fold_3 val\n",
      "Found 49 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 rimone fold_3 test\n",
      "Found 97 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 rimone fold_4 train\n",
      "Found 339 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 rimone fold_4 val\n",
      "Found 49 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 rimone fold_4 test\n",
      "Found 97 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 rimone fold_5 train\n",
      "Found 339 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 rimone fold_5 val\n",
      "Found 49 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 rimone fold_5 test\n",
      "Found 97 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 g1020 fold_1 train\n",
      "Found 714 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 g1020 fold_1 val\n",
      "Found 102 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 g1020 fold_1 test\n",
      "Found 204 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 g1020 fold_2 train\n",
      "Found 714 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 g1020 fold_2 val\n",
      "Found 102 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 g1020 fold_2 test\n",
      "Found 204 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 g1020 fold_3 train\n",
      "Found 714 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 g1020 fold_3 val\n",
      "Found 102 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 g1020 fold_3 test\n",
      "Found 204 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 g1020 fold_4 train\n",
      "Found 714 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 g1020 fold_4 val\n",
      "Found 102 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 g1020 fold_4 test\n",
      "Found 204 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 g1020 fold_5 train\n",
      "Found 714 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 g1020 fold_5 val\n",
      "Found 102 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 g1020 fold_5 test\n",
      "Found 204 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 refuge fold_1 train\n",
      "Found 840 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 refuge fold_1 val\n",
      "Found 120 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 refuge fold_1 test\n",
      "Found 240 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 refuge fold_2 train\n",
      "Found 840 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 refuge fold_2 val\n",
      "Found 120 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 refuge fold_2 test\n",
      "Found 240 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 refuge fold_3 train\n",
      "Found 840 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 refuge fold_3 val\n",
      "Found 120 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 refuge fold_3 test\n",
      "Found 240 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 refuge fold_4 train\n",
      "Found 840 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 refuge fold_4 val\n",
      "Found 120 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 refuge fold_4 test\n",
      "Found 240 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 refuge fold_5 train\n",
      "Found 840 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 refuge fold_5 val\n",
      "Found 120 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 refuge fold_5 test\n",
      "Found 240 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 papila fold_1 train\n",
      "Found 341 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 papila fold_1 val\n",
      "Found 49 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 papila fold_1 test\n",
      "Found 98 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 papila fold_2 train\n",
      "Found 341 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 papila fold_2 val\n",
      "Found 49 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 papila fold_2 test\n",
      "Found 98 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 papila fold_3 train\n",
      "Found 341 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 papila fold_3 val\n",
      "Found 49 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 papila fold_3 test\n",
      "Found 98 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 papila fold_4 train\n",
      "Found 342 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 papila fold_4 val\n",
      "Found 49 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 papila fold_4 test\n",
      "Found 97 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 papila fold_5 train\n",
      "Found 342 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 papila fold_5 val\n",
      "Found 49 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_1 papila fold_5 test\n",
      "Found 97 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 rimone fold_1 train_augmented\n",
      "Found 339 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 rimone fold_1 val\n",
      "Found 49 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 rimone fold_1 test\n",
      "Found 97 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 rimone fold_2 train_augmented\n",
      "Found 339 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 rimone fold_2 val\n",
      "Found 49 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 rimone fold_2 test\n",
      "Found 97 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 rimone fold_3 train_augmented\n",
      "Found 339 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 rimone fold_3 val\n",
      "Found 49 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 rimone fold_3 test\n",
      "Found 97 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 rimone fold_4 train_augmented\n",
      "Found 339 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 rimone fold_4 val\n",
      "Found 49 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 rimone fold_4 test\n",
      "Found 97 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 rimone fold_5 train_augmented\n",
      "Found 339 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 rimone fold_5 val\n",
      "Found 49 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 rimone fold_5 test\n",
      "Found 97 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 g1020 fold_1 train_augmented\n",
      "Found 714 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 g1020 fold_1 val\n",
      "Found 102 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 g1020 fold_1 test\n",
      "Found 204 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 g1020 fold_2 train_augmented\n",
      "Found 714 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 g1020 fold_2 val\n",
      "Found 102 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 g1020 fold_2 test\n",
      "Found 204 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 g1020 fold_3 train_augmented\n",
      "Found 714 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 g1020 fold_3 val\n",
      "Found 102 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 g1020 fold_3 test\n",
      "Found 204 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 g1020 fold_4 train_augmented\n",
      "Found 714 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 g1020 fold_4 val\n",
      "Found 102 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 g1020 fold_4 test\n",
      "Found 204 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 g1020 fold_5 train_augmented\n",
      "Found 714 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 g1020 fold_5 val\n",
      "Found 102 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 g1020 fold_5 test\n",
      "Found 204 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 refuge fold_1 train_augmented\n",
      "Found 840 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 refuge fold_1 val\n",
      "Found 120 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 refuge fold_1 test\n",
      "Found 240 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 refuge fold_2 train_augmented\n",
      "Found 840 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 refuge fold_2 val\n",
      "Found 120 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 refuge fold_2 test\n",
      "Found 240 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 refuge fold_3 train_augmented\n",
      "Found 840 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 refuge fold_3 val\n",
      "Found 120 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 refuge fold_3 test\n",
      "Found 240 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 refuge fold_4 train_augmented\n",
      "Found 840 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 refuge fold_4 val\n",
      "Found 120 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 refuge fold_4 test\n",
      "Found 240 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 refuge fold_5 train_augmented\n",
      "Found 840 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 refuge fold_5 val\n",
      "Found 120 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 refuge fold_5 test\n",
      "Found 240 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 papila fold_1 train_augmented\n",
      "Found 341 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 papila fold_1 val\n",
      "Found 49 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 papila fold_1 test\n",
      "Found 98 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 papila fold_2 train_augmented\n",
      "Found 341 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 papila fold_2 val\n",
      "Found 49 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 papila fold_2 test\n",
      "Found 98 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 papila fold_3 train_augmented\n",
      "Found 341 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 papila fold_3 val\n",
      "Found 49 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 papila fold_3 test\n",
      "Found 98 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 papila fold_4 train_augmented\n",
      "Found 342 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 papila fold_4 val\n",
      "Found 49 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 papila fold_4 test\n",
      "Found 97 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 papila fold_5 train_augmented\n",
      "Found 342 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 papila fold_5 val\n",
      "Found 49 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_2 papila fold_5 test\n",
      "Found 97 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 rimone fold_1 train_augmented\n",
      "Found 339 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 rimone fold_1 val\n",
      "Found 49 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 rimone fold_1 test\n",
      "Found 97 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 rimone fold_2 train_augmented\n",
      "Found 339 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 rimone fold_2 val\n",
      "Found 49 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 rimone fold_2 test\n",
      "Found 97 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 rimone fold_3 train_augmented\n",
      "Found 339 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 rimone fold_3 val\n",
      "Found 49 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 rimone fold_3 test\n",
      "Found 97 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 rimone fold_4 train_augmented\n",
      "Found 339 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 rimone fold_4 val\n",
      "Found 49 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 rimone fold_4 test\n",
      "Found 97 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 rimone fold_5 train_augmented\n",
      "Found 339 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 rimone fold_5 val\n",
      "Found 49 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 rimone fold_5 test\n",
      "Found 97 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 g1020 fold_1 train_augmented\n",
      "Found 714 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 g1020 fold_1 val\n",
      "Found 102 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 g1020 fold_1 test\n",
      "Found 204 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 g1020 fold_2 train_augmented\n",
      "Found 714 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 g1020 fold_2 val\n",
      "Found 102 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 g1020 fold_2 test\n",
      "Found 204 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 g1020 fold_3 train_augmented\n",
      "Found 714 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 g1020 fold_3 val\n",
      "Found 102 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 g1020 fold_3 test\n",
      "Found 204 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 g1020 fold_4 train_augmented\n",
      "Found 714 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 g1020 fold_4 val\n",
      "Found 102 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 g1020 fold_4 test\n",
      "Found 204 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 g1020 fold_5 train_augmented\n",
      "Found 714 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 g1020 fold_5 val\n",
      "Found 102 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 g1020 fold_5 test\n",
      "Found 204 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 refuge fold_1 train_augmented\n",
      "Found 840 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 refuge fold_1 val\n",
      "Found 120 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 refuge fold_1 test\n",
      "Found 240 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 refuge fold_2 train_augmented\n",
      "Found 840 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 refuge fold_2 val\n",
      "Found 120 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 refuge fold_2 test\n",
      "Found 240 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 refuge fold_3 train_augmented\n",
      "Found 840 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 refuge fold_3 val\n",
      "Found 120 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 refuge fold_3 test\n",
      "Found 240 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 refuge fold_4 train_augmented\n",
      "Found 840 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 refuge fold_4 val\n",
      "Found 120 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 refuge fold_4 test\n",
      "Found 240 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 refuge fold_5 train_augmented\n",
      "Found 840 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 refuge fold_5 val\n",
      "Found 120 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 refuge fold_5 test\n",
      "Found 240 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 papila fold_1 train_augmented\n",
      "Found 341 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 papila fold_1 val\n",
      "Found 49 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 papila fold_1 test\n",
      "Found 98 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 papila fold_2 train_augmented\n",
      "Found 341 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 papila fold_2 val\n",
      "Found 49 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 papila fold_2 test\n",
      "Found 98 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 papila fold_3 train_augmented\n",
      "Found 341 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 papila fold_3 val\n",
      "Found 49 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 papila fold_3 test\n",
      "Found 98 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 papila fold_4 train_augmented\n",
      "Found 342 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 papila fold_4 val\n",
      "Found 49 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 papila fold_4 test\n",
      "Found 97 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 papila fold_5 train_augmented\n",
      "Found 342 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 papila fold_5 val\n",
      "Found 49 images belonging to 2 classes.\n",
      "Creating image data generator for scenario_3 papila fold_5 test\n",
      "Found 97 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "img_gen = modeling.datagen(scenario_names=scenario_names,\n",
    "                            dataset_names=dataset_names,\n",
    "                            fold_names=fold_names,\n",
    "                            path_dataset_src=path_dataset_src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "#### Prepare the variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scenario 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mobilenet V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Dataset: rimone\n",
      "Fold: 1\n",
      "Training f1 finished in 133.46 seconds\n",
      "Saving f1 finished in 4.16 seconds\n",
      "Fold: 2\n",
      "Training f2 finished in 101.84 seconds\n",
      "Saving f2 finished in 4.11 seconds\n",
      "Fold: 3\n",
      "Training f3 finished in 98.77 seconds\n",
      "Saving f3 finished in 3.83 seconds\n",
      "Fold: 4\n",
      "Training f4 finished in 97.2 seconds\n",
      "Saving f4 finished in 3.7 seconds\n",
      "Fold: 5\n",
      "Training f5 finished in 95.22 seconds\n",
      "Saving f5 finished in 3.57 seconds\n",
      "\n",
      "\n",
      "Dataset: g1020\n",
      "Fold: 1\n",
      "Training f1 finished in 1242.2 seconds\n",
      "Saving f1 finished in 10.38 seconds\n",
      "Fold: 2\n",
      "Training f2 finished in 1152.53 seconds\n",
      "Saving f2 finished in 7.13 seconds\n",
      "Fold: 3\n",
      "Training f3 finished in 1080.07 seconds\n",
      "Saving f3 finished in 4.94 seconds\n",
      "Fold: 4\n",
      "Training f4 finished in 500.18 seconds\n",
      "Saving f4 finished in 5.24 seconds\n",
      "Fold: 5\n",
      "Training f5 finished in 828.83 seconds\n",
      "Saving f5 finished in 4.6 seconds\n",
      "\n",
      "\n",
      "Dataset: refuge\n",
      "Fold: 1\n",
      "Training f1 finished in 651.61 seconds\n",
      "Saving f1 finished in 5.4 seconds\n",
      "Fold: 2\n",
      "Training f2 finished in 1413.05 seconds\n",
      "Saving f2 finished in 9.23 seconds\n",
      "Fold: 3\n",
      "Training f3 finished in 1222.01 seconds\n",
      "Saving f3 finished in 5.95 seconds\n",
      "Fold: 4\n",
      "Training f4 finished in 1129.0 seconds\n",
      "Saving f4 finished in 7.43 seconds\n",
      "Fold: 5\n",
      "Training f5 finished in 621.31 seconds\n",
      "Saving f5 finished in 3.66 seconds\n",
      "\n",
      "\n",
      "Dataset: papila\n",
      "Fold: 1\n",
      "Training f1 finished in 253.53 seconds\n",
      "Saving f1 finished in 3.27 seconds\n",
      "Fold: 2\n",
      "Training f2 finished in 248.88 seconds\n",
      "Saving f2 finished in 3.81 seconds\n",
      "Fold: 3\n",
      "Training f3 finished in 235.48 seconds\n",
      "Saving f3 finished in 2.85 seconds\n",
      "Fold: 4\n",
      "Training f4 finished in 227.25 seconds\n",
      "Saving f4 finished in 2.41 seconds\n",
      "Fold: 5\n",
      "Training f5 finished in 239.44 seconds\n",
      "Saving f5 finished in 3.32 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train the model with all dataset\n",
    "model = pre_trained_models[0]\n",
    "model_base_name = f's{scenario_names[0].split(\"_\")[-1]}_{model}'\n",
    "for dataset in dataset_names:\n",
    "    print(f'\\n\\nDataset: {dataset}')\n",
    "\n",
    "    for fold in fold_names:\n",
    "        print(f'Fold: {fold.split(\"_\")[-1]}')\n",
    "\n",
    "        # Train the model\n",
    "        history = modeling.train_model(pre_trained=model,\n",
    "                                        model_src=path_pretrained,\n",
    "                                        model_dest=path_model_storage,\n",
    "                                        model_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',\n",
    "                                        datagen_train=img_gen[f'scenario_1_{dataset}_{fold}_train'],\n",
    "                                        datagen_val=img_gen[f'scenario_1_{dataset}_{fold}_val'])\n",
    "        # Store the result\n",
    "        modeling.train_result(result=history,\n",
    "                            path_store=path_result,\n",
    "                            type_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',)\n",
    "del dataset, fold, history, model, model_base_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mobilenet V2 small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Dataset: rimone\n",
      "Fold: 1\n",
      "Training f1 finished in 103.09 seconds\n",
      "Saving f1 finished in 2.43 seconds\n",
      "Fold: 2\n",
      "Training f2 finished in 74.71 seconds\n",
      "Saving f2 finished in 2.25 seconds\n",
      "Fold: 3\n",
      "Training f3 finished in 67.26 seconds\n",
      "Saving f3 finished in 2.2 seconds\n",
      "Fold: 4\n",
      "Training f4 finished in 68.52 seconds\n",
      "Saving f4 finished in 2.93 seconds\n",
      "Fold: 5\n",
      "Training f5 finished in 73.89 seconds\n",
      "Saving f5 finished in 4.73 seconds\n",
      "\n",
      "\n",
      "Dataset: g1020\n",
      "Fold: 1\n",
      "Training f1 finished in 564.7 seconds\n",
      "Saving f1 finished in 2.39 seconds\n",
      "Fold: 2\n",
      "Training f2 finished in 447.52 seconds\n",
      "Saving f2 finished in 3.62 seconds\n",
      "Fold: 3\n",
      "Training f3 finished in 444.84 seconds\n",
      "Saving f3 finished in 2.15 seconds\n",
      "Fold: 4\n",
      "Training f4 finished in 471.97 seconds\n",
      "Saving f4 finished in 2.03 seconds\n",
      "Fold: 5\n",
      "Training f5 finished in 666.32 seconds\n",
      "Saving f5 finished in 2.56 seconds\n",
      "\n",
      "\n",
      "Dataset: refuge\n",
      "Fold: 1\n",
      "Training f1 finished in 791.07 seconds\n",
      "Saving f1 finished in 5.32 seconds\n",
      "Fold: 2\n",
      "Training f2 finished in 1008.17 seconds\n",
      "Saving f2 finished in 12.86 seconds\n",
      "Fold: 3\n",
      "Training f3 finished in 1548.7 seconds\n",
      "Saving f3 finished in 9.88 seconds\n",
      "Fold: 4\n",
      "Training f4 finished in 1606.32 seconds\n",
      "Saving f4 finished in 13.16 seconds\n",
      "Fold: 5\n",
      "Training f5 finished in 2239.93 seconds\n",
      "Saving f5 finished in 14.48 seconds\n",
      "\n",
      "\n",
      "Dataset: papila\n",
      "Fold: 1\n",
      "Training f1 finished in 815.77 seconds\n",
      "Saving f1 finished in 4.46 seconds\n",
      "Fold: 2\n",
      "Training f2 finished in 324.2 seconds\n",
      "Saving f2 finished in 3.64 seconds\n",
      "Fold: 3\n",
      "Training f3 finished in 271.92 seconds\n",
      "Saving f3 finished in 5.38 seconds\n",
      "Fold: 4\n",
      "Training f4 finished in 241.1 seconds\n",
      "Saving f4 finished in 2.89 seconds\n",
      "Fold: 5\n",
      "Training f5 finished in 213.2 seconds\n",
      "Saving f5 finished in 5.07 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train the model with all dataset\n",
    "model = pre_trained_models[1]\n",
    "model_base_name = f's{scenario_names[0].split(\"_\")[-1]}_{model}'\n",
    "for dataset in dataset_names:\n",
    "    print(f'\\n\\nDataset: {dataset}')\n",
    "\n",
    "    for fold in fold_names:\n",
    "        print(f'Fold: {fold.split(\"_\")[-1]}')\n",
    "\n",
    "        # Train the model\n",
    "        history = modeling.train_model(pre_trained=model,\n",
    "                                        model_src=path_pretrained,\n",
    "                                        model_dest=path_model_storage,\n",
    "                                        model_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',\n",
    "                                        datagen_train=img_gen[f'scenario_1_{dataset}_{fold}_train'],\n",
    "                                        datagen_val=img_gen[f'scenario_1_{dataset}_{fold}_val'])\n",
    "        # Store the result\n",
    "        modeling.train_result(result=history,\n",
    "                            path_store=path_result,\n",
    "                            type_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',)\n",
    "del dataset, fold, history, model, model_base_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mobilenet V2 large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Dataset: rimone\n",
      "Fold: 1\n",
      "Training f1 finished in 81.57 seconds\n",
      "Saving f1 finished in 2.45 seconds\n",
      "Fold: 2\n",
      "Training f2 finished in 75.32 seconds\n",
      "Saving f2 finished in 2.2 seconds\n",
      "Fold: 3\n",
      "Training f3 finished in 74.3 seconds\n",
      "Saving f3 finished in 2.2 seconds\n",
      "Fold: 4\n",
      "Training f4 finished in 76.49 seconds\n",
      "Saving f4 finished in 3.35 seconds\n",
      "Fold: 5\n",
      "Training f5 finished in 76.27 seconds\n",
      "Saving f5 finished in 2.72 seconds\n",
      "\n",
      "\n",
      "Dataset: g1020\n",
      "Fold: 1\n",
      "Training f1 finished in 521.02 seconds\n",
      "Saving f1 finished in 2.24 seconds\n",
      "Fold: 2\n",
      "Training f2 finished in 563.27 seconds\n",
      "Saving f2 finished in 3.01 seconds\n",
      "Fold: 3\n",
      "Training f3 finished in 1439.47 seconds\n",
      "Saving f3 finished in 11.19 seconds\n",
      "Fold: 4\n",
      "Training f4 finished in 1311.14 seconds\n",
      "Saving f4 finished in 4.67 seconds\n",
      "Fold: 5\n",
      "Training f5 finished in 742.44 seconds\n",
      "Saving f5 finished in 4.79 seconds\n",
      "\n",
      "\n",
      "Dataset: refuge\n",
      "Fold: 1\n",
      "Training f1 finished in 633.78 seconds\n",
      "Saving f1 finished in 4.55 seconds\n",
      "Fold: 2\n",
      "Training f2 finished in 645.5 seconds\n",
      "Saving f2 finished in 4.04 seconds\n",
      "Fold: 3\n",
      "Training f3 finished in 632.59 seconds\n",
      "Saving f3 finished in 3.97 seconds\n",
      "Fold: 4\n",
      "Training f4 finished in 466.61 seconds\n",
      "Saving f4 finished in 2.25 seconds\n",
      "Fold: 5\n",
      "Training f5 finished in 56810.82 seconds\n",
      "Saving f5 finished in 4.41 seconds\n",
      "\n",
      "\n",
      "Dataset: papila\n",
      "Fold: 1\n",
      "Training f1 finished in 293.24 seconds\n",
      "Saving f1 finished in 2.46 seconds\n",
      "Fold: 2\n",
      "Training f2 finished in 318.46 seconds\n",
      "Saving f2 finished in 3.44 seconds\n",
      "Fold: 3\n",
      "Training f3 finished in 258.01 seconds\n",
      "Saving f3 finished in 2.96 seconds\n",
      "Fold: 4\n",
      "Training f4 finished in 255.59 seconds\n",
      "Saving f4 finished in 2.89 seconds\n",
      "Fold: 5\n",
      "Training f5 finished in 273.7 seconds\n",
      "Saving f5 finished in 3.42 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train the model with all dataset\n",
    "model = pre_trained_models[2]\n",
    "model_base_name = f's{scenario_names[0].split(\"_\")[-1]}_{model}'\n",
    "for dataset in dataset_names:\n",
    "    print(f'\\n\\nDataset: {dataset}')\n",
    "\n",
    "    for fold in fold_names:\n",
    "        print(f'Fold: {fold.split(\"_\")[-1]}')\n",
    "\n",
    "        # Train the model\n",
    "        history = modeling.train_model(pre_trained=model,\n",
    "                                        model_src=path_pretrained,\n",
    "                                        model_dest=path_model_storage,\n",
    "                                        model_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',\n",
    "                                        datagen_train=img_gen[f'scenario_1_{dataset}_{fold}_train'],\n",
    "                                        datagen_val=img_gen[f'scenario_1_{dataset}_{fold}_val'])\n",
    "        # Store the result\n",
    "        modeling.train_result(result=history,\n",
    "                            path_store=path_result,\n",
    "                            type_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',)\n",
    "del dataset, fold, history, model, model_base_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Efficientnet V2 small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Dataset: rimone\n",
      "Fold: 1\n",
      "Training f1 finished in 121.07 seconds\n",
      "Saving f1 finished in 2.56 seconds\n",
      "Fold: 2\n",
      "Training f2 finished in 98.8 seconds\n",
      "Saving f2 finished in 2.2 seconds\n",
      "Fold: 3\n",
      "Training f3 finished in 103.79 seconds\n",
      "Saving f3 finished in 2.25 seconds\n",
      "Fold: 4\n",
      "Training f4 finished in 98.99 seconds\n",
      "Saving f4 finished in 3.73 seconds\n",
      "Fold: 5\n",
      "Training f5 finished in 101.16 seconds\n",
      "Saving f5 finished in 2.23 seconds\n",
      "\n",
      "\n",
      "Dataset: g1020\n",
      "Fold: 1\n",
      "Training f1 finished in 519.94 seconds\n",
      "Saving f1 finished in 2.01 seconds\n",
      "Fold: 2\n",
      "Training f2 finished in 445.81 seconds\n",
      "Saving f2 finished in 1.94 seconds\n",
      "Fold: 3\n",
      "Training f3 finished in 458.95 seconds\n",
      "Saving f3 finished in 2.54 seconds\n",
      "Fold: 4\n",
      "Training f4 finished in 497.93 seconds\n",
      "Saving f4 finished in 2.01 seconds\n",
      "Fold: 5\n",
      "Training f5 finished in 452.8 seconds\n",
      "Saving f5 finished in 1.9 seconds\n",
      "\n",
      "\n",
      "Dataset: refuge\n",
      "Fold: 1\n",
      "Training f1 finished in 395.26 seconds\n",
      "Saving f1 finished in 1.93 seconds\n",
      "Fold: 2\n",
      "Training f2 finished in 398.61 seconds\n",
      "Saving f2 finished in 1.93 seconds\n",
      "Fold: 3\n",
      "Training f3 finished in 446.21 seconds\n",
      "Saving f3 finished in 1.94 seconds\n",
      "Fold: 4\n",
      "Training f4 finished in 408.9 seconds\n",
      "Saving f4 finished in 1.95 seconds\n",
      "Fold: 5\n",
      "Training f5 finished in 511.24 seconds\n",
      "Saving f5 finished in 2.32 seconds\n",
      "\n",
      "\n",
      "Dataset: papila\n",
      "Fold: 1\n",
      "Training f1 finished in 243.76 seconds\n",
      "Saving f1 finished in 3.31 seconds\n",
      "Fold: 2\n",
      "Training f2 finished in 237.71 seconds\n",
      "Saving f2 finished in 2.18 seconds\n",
      "Fold: 3\n",
      "Training f3 finished in 232.33 seconds\n",
      "Saving f3 finished in 2.08 seconds\n",
      "Fold: 4\n",
      "Training f4 finished in 221.38 seconds\n",
      "Saving f4 finished in 2.18 seconds\n",
      "Fold: 5\n",
      "Training f5 finished in 223.94 seconds\n",
      "Saving f5 finished in 1.88 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train the model with all dataset\n",
    "model = pre_trained_models[3]\n",
    "model_base_name = f's{scenario_names[0].split(\"_\")[-1]}_{model}'\n",
    "for dataset in dataset_names:\n",
    "    print(f'\\n\\nDataset: {dataset}')\n",
    "\n",
    "    for fold in fold_names:\n",
    "        print(f'Fold: {fold.split(\"_\")[-1]}')\n",
    "\n",
    "        # Train the model\n",
    "        history = modeling.train_model(pre_trained=model,\n",
    "                                        model_src=path_pretrained,\n",
    "                                        model_dest=path_model_storage,\n",
    "                                        model_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',\n",
    "                                        datagen_train=img_gen[f'scenario_1_{dataset}_{fold}_train'],\n",
    "                                        datagen_val=img_gen[f'scenario_1_{dataset}_{fold}_val'])\n",
    "        # Store the result\n",
    "        modeling.train_result(result=history,\n",
    "                            path_store=path_result,\n",
    "                            type_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',)\n",
    "del dataset, fold, history, model, model_base_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Efficientnet V2 middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Dataset: rimone\n",
      "Fold: 1\n",
      "Training f1 finished in 154.84 seconds\n",
      "Saving f1 finished in 2.49 seconds\n",
      "Fold: 2\n",
      "Training f2 finished in 147.81 seconds\n",
      "Saving f2 finished in 2.36 seconds\n",
      "Fold: 3\n",
      "Training f3 finished in 146.5 seconds\n",
      "Saving f3 finished in 2.41 seconds\n",
      "Fold: 4\n",
      "Training f4 finished in 148.13 seconds\n",
      "Saving f4 finished in 2.64 seconds\n",
      "Fold: 5\n",
      "Training f5 finished in 248.66 seconds\n",
      "Saving f5 finished in 3.95 seconds\n",
      "\n",
      "\n",
      "Dataset: g1020\n",
      "Fold: 1\n",
      "Training f1 finished in 1238.22 seconds\n",
      "Saving f1 finished in 8.43 seconds\n",
      "Fold: 2\n",
      "Training f2 finished in 1224.21 seconds\n",
      "Saving f2 finished in 6.19 seconds\n",
      "Fold: 3\n",
      "Training f3 finished in 730.21 seconds\n",
      "Saving f3 finished in 2.65 seconds\n",
      "Fold: 4\n",
      "Training f4 finished in 569.73 seconds\n",
      "Saving f4 finished in 2.3 seconds\n",
      "Fold: 5\n",
      "Training f5 finished in 580.73 seconds\n",
      "Saving f5 finished in 10.82 seconds\n",
      "\n",
      "\n",
      "Dataset: refuge\n",
      "Fold: 1\n",
      "Training f1 finished in 721.3 seconds\n",
      "Saving f1 finished in 2.8 seconds\n",
      "Fold: 2\n",
      "Training f2 finished in 594.59 seconds\n",
      "Saving f2 finished in 3.24 seconds\n",
      "Fold: 3\n",
      "Training f3 finished in 637.82 seconds\n",
      "Saving f3 finished in 2.93 seconds\n",
      "Fold: 4\n",
      "Training f4 finished in 657.99 seconds\n",
      "Saving f4 finished in 2.78 seconds\n",
      "Fold: 5\n",
      "Training f5 finished in 642.75 seconds\n",
      "Saving f5 finished in 2.99 seconds\n",
      "\n",
      "\n",
      "Dataset: papila\n",
      "Fold: 1\n",
      "Training f1 finished in 308.13 seconds\n",
      "Saving f1 finished in 2.55 seconds\n",
      "Fold: 2\n",
      "Training f2 finished in 303.75 seconds\n",
      "Saving f2 finished in 2.28 seconds\n",
      "Fold: 3\n",
      "Training f3 finished in 266.42 seconds\n",
      "Saving f3 finished in 2.17 seconds\n",
      "Fold: 4\n",
      "Training f4 finished in 263.09 seconds\n",
      "Saving f4 finished in 2.72 seconds\n",
      "Fold: 5\n",
      "Training f5 finished in 520.74 seconds\n",
      "Saving f5 finished in 7.87 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train the model with all dataset\n",
    "model = pre_trained_models[4]\n",
    "model_base_name = f's{scenario_names[0].split(\"_\")[-1]}_{model}'\n",
    "for dataset in dataset_names:\n",
    "    print(f'\\n\\nDataset: {dataset}')\n",
    "\n",
    "    for fold in fold_names:\n",
    "        print(f'Fold: {fold.split(\"_\")[-1]}')\n",
    "\n",
    "        # Train the model\n",
    "        history = modeling.train_model(pre_trained=model,\n",
    "                                        model_src=path_pretrained,\n",
    "                                        model_dest=path_model_storage,\n",
    "                                        model_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',\n",
    "                                        datagen_train=img_gen[f'scenario_1_{dataset}_{fold}_train'],\n",
    "                                        datagen_val=img_gen[f'scenario_1_{dataset}_{fold}_val'])\n",
    "        # Store the result\n",
    "        modeling.train_result(result=history,\n",
    "                            path_store=path_result,\n",
    "                            type_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',)\n",
    "del dataset, fold, history, model, model_base_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Efficientnet V2 large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with all dataset\n",
    "model = pre_trained_models[5]\n",
    "model_base_name = f's{scenario_names[0].split(\"_\")[-1]}_{model}'\n",
    "for dataset in dataset_names:\n",
    "    print(f'\\n\\nDataset: {dataset}')\n",
    "\n",
    "    for fold in fold_names:\n",
    "        print(f'Fold: {fold.split(\"_\")[-1]}')\n",
    "\n",
    "        # Train the model\n",
    "        history = modeling.train_model(pre_trained=model,\n",
    "                                        model_src=path_pretrained,\n",
    "                                        model_dest=path_model_storage,\n",
    "                                        model_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',\n",
    "                                        datagen_train=img_gen[f'scenario_1_{dataset}_{fold}_train'],\n",
    "                                        datagen_val=img_gen[f'scenario_1_{dataset}_{fold}_val'])\n",
    "        # Store the result\n",
    "        modeling.train_result(result=history,\n",
    "                            path_store=path_result,\n",
    "                            type_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',)\n",
    "del dataset, fold, history, model, model_base_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scenario 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mobilenet V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with all dataset\n",
    "model = pre_trained_models[0]\n",
    "model_base_name = f's{scenario_names[1].split(\"_\")[-1]}_{model}'\n",
    "for dataset in dataset_names:\n",
    "    print(f'\\n\\nDataset: {dataset}')\n",
    "\n",
    "    for fold in fold_names:\n",
    "        print(f'Fold: {fold.split(\"_\")[-1]}')\n",
    "\n",
    "        # Train the model\n",
    "        history = modeling.train_model(pre_trained=model,\n",
    "                                        model_src=path_pretrained,\n",
    "                                        model_dest=path_model_storage,\n",
    "                                        model_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',\n",
    "                                        datagen_train=img_gen[f'scenario_2_{dataset}_{fold}_train'],\n",
    "                                        datagen_val=img_gen[f'scenario_2_{dataset}_{fold}_val'])\n",
    "        # Store the result\n",
    "        modeling.train_result(result=history,\n",
    "                            path_store=path_result,\n",
    "                            type_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',)\n",
    "del dataset, fold, history, model, model_base_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mobilenet V2 small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with all dataset\n",
    "model = pre_trained_models[1]\n",
    "model_base_name = f's{scenario_names[1].split(\"_\")[-1]}_{model}'\n",
    "for dataset in dataset_names:\n",
    "    print(f'\\n\\nDataset: {dataset}')\n",
    "\n",
    "    for fold in fold_names:\n",
    "        print(f'Fold: {fold.split(\"_\")[-1]}')\n",
    "\n",
    "        # Train the model\n",
    "        history = modeling.train_model(pre_trained=model,\n",
    "                                        model_src=path_pretrained,\n",
    "                                        model_dest=path_model_storage,\n",
    "                                        model_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',\n",
    "                                        datagen_train=img_gen[f'scenario_2_{dataset}_{fold}_train'],\n",
    "                                        datagen_val=img_gen[f'scenario_2_{dataset}_{fold}_val'])\n",
    "        # Store the result\n",
    "        modeling.train_result(result=history,\n",
    "                            path_store=path_result,\n",
    "                            type_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',)\n",
    "del dataset, fold, history, model, model_base_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mobilenet V2 large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with all dataset\n",
    "model = pre_trained_models[2]\n",
    "model_base_name = f's{scenario_names[1].split(\"_\")[-1]}_{model}'\n",
    "for dataset in dataset_names:\n",
    "    print(f'\\n\\nDataset: {dataset}')\n",
    "\n",
    "    for fold in fold_names:\n",
    "        print(f'Fold: {fold.split(\"_\")[-1]}')\n",
    "\n",
    "        # Train the model\n",
    "        history = modeling.train_model(pre_trained=model,\n",
    "                                        model_src=path_pretrained,\n",
    "                                        model_dest=path_model_storage,\n",
    "                                        model_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',\n",
    "                                        datagen_train=img_gen[f'scenario_2_{dataset}_{fold}_train'],\n",
    "                                        datagen_val=img_gen[f'scenario_2_{dataset}_{fold}_val'])\n",
    "        # Store the result\n",
    "        modeling.train_result(result=history,\n",
    "                            path_store=path_result,\n",
    "                            type_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',)\n",
    "del dataset, fold, history, model, model_base_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Efficientnet V2 small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with all dataset\n",
    "model = pre_trained_models[3]\n",
    "model_base_name = f's{scenario_names[1].split(\"_\")[-1]}_{model}'\n",
    "for dataset in dataset_names:\n",
    "    print(f'\\n\\nDataset: {dataset}')\n",
    "\n",
    "    for fold in fold_names:\n",
    "        print(f'Fold: {fold.split(\"_\")[-1]}')\n",
    "\n",
    "        # Train the model\n",
    "        history = modeling.train_model(pre_trained=model,\n",
    "                                        model_src=path_pretrained,\n",
    "                                        model_dest=path_model_storage,\n",
    "                                        model_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',\n",
    "                                        datagen_train=img_gen[f'scenario_2_{dataset}_{fold}_train'],\n",
    "                                        datagen_val=img_gen[f'scenario_2_{dataset}_{fold}_val'])\n",
    "        # Store the result\n",
    "        modeling.train_result(result=history,\n",
    "                            path_store=path_result,\n",
    "                            type_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',)\n",
    "del dataset, fold, history, model, model_base_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Efficientnet V2 middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with all dataset\n",
    "model = pre_trained_models[4]\n",
    "model_base_name = f's{scenario_names[1].split(\"_\")[-1]}_{model}'\n",
    "for dataset in dataset_names:\n",
    "    print(f'\\n\\nDataset: {dataset}')\n",
    "\n",
    "    for fold in fold_names:\n",
    "        print(f'Fold: {fold.split(\"_\")[-1]}')\n",
    "\n",
    "        # Train the model\n",
    "        history = modeling.train_model(pre_trained=model,\n",
    "                                        model_src=path_pretrained,\n",
    "                                        model_dest=path_model_storage,\n",
    "                                        model_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',\n",
    "                                        datagen_train=img_gen[f'scenario_2_{dataset}_{fold}_train'],\n",
    "                                        datagen_val=img_gen[f'scenario_2_{dataset}_{fold}_val'])\n",
    "        # Store the result\n",
    "        modeling.train_result(result=history,\n",
    "                            path_store=path_result,\n",
    "                            type_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',)\n",
    "del dataset, fold, history, model, model_base_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Efficientnet V2 large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with all dataset\n",
    "model = pre_trained_models[5]\n",
    "model_base_name = f's{scenario_names[1].split(\"_\")[-1]}_{model}'\n",
    "for dataset in dataset_names:\n",
    "    print(f'\\n\\nDataset: {dataset}')\n",
    "\n",
    "    for fold in fold_names:\n",
    "        print(f'Fold: {fold.split(\"_\")[-1]}')\n",
    "\n",
    "        # Train the model\n",
    "        history = modeling.train_model(pre_trained=model,\n",
    "                                        model_src=path_pretrained,\n",
    "                                        model_dest=path_model_storage,\n",
    "                                        model_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',\n",
    "                                        datagen_train=img_gen[f'scenario_2_{dataset}_{fold}_train'],\n",
    "                                        datagen_val=img_gen[f'scenario_2_{dataset}_{fold}_val'])\n",
    "        # Store the result\n",
    "        modeling.train_result(result=history,\n",
    "                            path_store=path_result,\n",
    "                            type_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',)\n",
    "del dataset, fold, history, model, model_base_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scenario 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mobilenet V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with all dataset\n",
    "model = pre_trained_models[0]\n",
    "model_base_name = f's{scenario_names[2].split(\"_\")[-1]}_{model}'\n",
    "for dataset in dataset_names:\n",
    "    print(f'\\n\\nDataset: {dataset}')\n",
    "\n",
    "    for fold in fold_names:\n",
    "        print(f'Fold: {fold.split(\"_\")[-1]}')\n",
    "\n",
    "        # Train the model\n",
    "        history = modeling.train_model(pre_trained=model,\n",
    "                                        model_src=path_pretrained,\n",
    "                                        model_dest=path_model_storage,\n",
    "                                        model_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',\n",
    "                                        datagen_train=img_gen[f'scenario_3_{dataset}_{fold}_train'],\n",
    "                                        datagen_val=img_gen[f'scenario_3_{dataset}_{fold}_val'])\n",
    "        # Store the result\n",
    "        modeling.train_result(result=history,\n",
    "                            path_store=path_result,\n",
    "                            type_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',)\n",
    "del dataset, fold, history, model, model_base_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mobilenet V2 small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with all dataset\n",
    "model = pre_trained_models[1]\n",
    "model_base_name = f's{scenario_names[2].split(\"_\")[-1]}_{model}'\n",
    "for dataset in dataset_names:\n",
    "    print(f'\\n\\nDataset: {dataset}')\n",
    "\n",
    "    for fold in fold_names:\n",
    "        print(f'Fold: {fold.split(\"_\")[-1]}')\n",
    "\n",
    "        # Train the model\n",
    "        history = modeling.train_model(pre_trained=model,\n",
    "                                        model_src=path_pretrained,\n",
    "                                        model_dest=path_model_storage,\n",
    "                                        model_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',\n",
    "                                        datagen_train=img_gen[f'scenario_3_{dataset}_{fold}_train'],\n",
    "                                        datagen_val=img_gen[f'scenario_3_{dataset}_{fold}_val'])\n",
    "        # Store the result\n",
    "        modeling.train_result(result=history,\n",
    "                            path_store=path_result,\n",
    "                            type_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',)\n",
    "del dataset, fold, history, model, model_base_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mobilenet V2 large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with all dataset\n",
    "model = pre_trained_models[2]\n",
    "model_base_name = f's{scenario_names[2].split(\"_\")[-1]}_{model}'\n",
    "for dataset in dataset_names:\n",
    "    print(f'\\n\\nDataset: {dataset}')\n",
    "\n",
    "    for fold in fold_names:\n",
    "        print(f'Fold: {fold.split(\"_\")[-1]}')\n",
    "\n",
    "        # Train the model\n",
    "        history = modeling.train_model(pre_trained=model,\n",
    "                                        model_src=path_pretrained,\n",
    "                                        model_dest=path_model_storage,\n",
    "                                        model_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',\n",
    "                                        datagen_train=img_gen[f'scenario_3_{dataset}_{fold}_train'],\n",
    "                                        datagen_val=img_gen[f'scenario_3_{dataset}_{fold}_val'])\n",
    "        # Store the result\n",
    "        modeling.train_result(result=history,\n",
    "                            path_store=path_result,\n",
    "                            type_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',)\n",
    "del dataset, fold, history, model, model_base_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Efficientnet V2 small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with all dataset\n",
    "model = pre_trained_models[3]\n",
    "model_base_name = f's{scenario_names[2].split(\"_\")[-1]}_{model}'\n",
    "for dataset in dataset_names:\n",
    "    print(f'\\n\\nDataset: {dataset}')\n",
    "\n",
    "    for fold in fold_names:\n",
    "        print(f'Fold: {fold.split(\"_\")[-1]}')\n",
    "\n",
    "        # Train the model\n",
    "        history = modeling.train_model(pre_trained=model,\n",
    "                                        model_src=path_pretrained,\n",
    "                                        model_dest=path_model_storage,\n",
    "                                        model_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',\n",
    "                                        datagen_train=img_gen[f'scenario_3_{dataset}_{fold}_train'],\n",
    "                                        datagen_val=img_gen[f'scenario_3_{dataset}_{fold}_val'])\n",
    "        # Store the result\n",
    "        modeling.train_result(result=history,\n",
    "                            path_store=path_result,\n",
    "                            type_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',)\n",
    "del dataset, fold, history, model, model_base_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Efficientnet V2 middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with all dataset\n",
    "model = pre_trained_models[4]\n",
    "model_base_name = f's{scenario_names[2].split(\"_\")[-1]}_{model}'\n",
    "for dataset in dataset_names:\n",
    "    print(f'\\n\\nDataset: {dataset}')\n",
    "\n",
    "    for fold in fold_names:\n",
    "        print(f'Fold: {fold.split(\"_\")[-1]}')\n",
    "\n",
    "        # Train the model\n",
    "        history = modeling.train_model(pre_trained=model,\n",
    "                                        model_src=path_pretrained,\n",
    "                                        model_dest=path_model_storage,\n",
    "                                        model_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',\n",
    "                                        datagen_train=img_gen[f'scenario_3_{dataset}_{fold}_train'],\n",
    "                                        datagen_val=img_gen[f'scenario_3_{dataset}_{fold}_val'])\n",
    "        # Store the result\n",
    "        modeling.train_result(result=history,\n",
    "                            path_store=path_result,\n",
    "                            type_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',)\n",
    "del dataset, fold, history, model, model_base_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Efficientnet V2 large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with all dataset\n",
    "model = pre_trained_models[5]\n",
    "model_base_name = f's{scenario_names[2].split(\"_\")[-1]}_{model}'\n",
    "for dataset in dataset_names:\n",
    "    print(f'\\n\\nDataset: {dataset}')\n",
    "\n",
    "    for fold in fold_names:\n",
    "        print(f'Fold: {fold.split(\"_\")[-1]}')\n",
    "\n",
    "        # Train the model\n",
    "        history = modeling.train_model(pre_trained=model,\n",
    "                                        model_src=path_pretrained,\n",
    "                                        model_dest=path_model_storage,\n",
    "                                        model_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',\n",
    "                                        datagen_train=img_gen[f'scenario_3_{dataset}_{fold}_train'],\n",
    "                                        datagen_val=img_gen[f'scenario_3_{dataset}_{fold}_val'])\n",
    "        # Store the result\n",
    "        modeling.train_result(result=history,\n",
    "                            path_store=path_result,\n",
    "                            type_name=f'{model_base_name}_{dataset}_f{fold.split(\"_\")[-1]}',)\n",
    "del dataset, fold, history, model, model_base_name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_skripsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
